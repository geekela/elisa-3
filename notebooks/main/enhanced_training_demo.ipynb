{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Ring Attractor Network Training\n",
    "## Adam Optimizer with Cosine Annealing Learning Rate Schedule\n",
    "\n",
    "This notebook demonstrates the enhanced training system for ring attractor networks, featuring:\n",
    "\n",
    "- **Adam Optimizer**: Adaptive learning rate with momentum and RMSprop components\n",
    "- **Cosine Annealing**: Smooth learning rate decay for better convergence\n",
    "- **Biological Constraints**: Ensures parameters remain biologically plausible\n",
    "- **Comprehensive Monitoring**: Track training progress, gradients, and network parameters\n",
    "- **Interactive Visualization**: Real-time plots of training metrics\n",
    "\n",
    "### Mathematical Background\n",
    "\n",
    "**Adam Optimizer Updates:**\n",
    "```\n",
    "m_t = β₁ * m_{t-1} + (1 - β₁) * g_t          # Momentum\n",
    "v_t = β₂ * v_{t-1} + (1 - β₂) * g_t²         # RMSprop\n",
    "m̂_t = m_t / (1 - β₁^t)                       # Bias correction\n",
    "v̂_t = v_t / (1 - β₂^t)                       # Bias correction\n",
    "θ_t = θ_{t-1} - α * m̂_t / (√v̂_t + ε)         # Parameter update\n",
    "```\n",
    "\n",
    "**Cosine Annealing Learning Rate:**\n",
    "```\n",
    "η_t = η_min + (η_max - η_min) * (1 + cos(πt/T)) / 2\n",
    "```\n",
    "\n",
    "Where `T` is the total number of epochs and `t` is the current epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to Python path: /workspace/elisa-3/src\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/elisa-3/src/hd_ring_attractor/training/enhanced_training.py:12\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m angle_to_input, generate_trajectory, compute_error\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# Fallback for when module is imported directly (e.g., in Jupyter notebooks)\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'hd_ring_attractor.training.utils'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Import your ring attractor modules with correct paths\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhd_ring_attractor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RingAttractorNetwork\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhd_ring_attractor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menhanced_training\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdamCosineTrainer, create_training_config, train_ring_attractor_with_adam_cosine\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhd_ring_attractor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_model  \u001b[38;5;66;03m# Original training for comparison\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhd_ring_attractor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generate_trajectory, angle_to_input, compute_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/elisa-3/src/hd_ring_attractor/training/enhanced_training.py:15\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m angle_to_input, generate_trajectory, compute_error\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# Fallback for when module is imported directly (e.g., in Jupyter notebooks)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m angle_to_input, generate_trajectory, compute_error\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mAdamCosineTrainer\u001b[39;00m:\n\u001b[32m     19\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33;03m    Enhanced trainer for Ring Attractor Network using Adam optimizer \u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[33;03m    with cosine annealing learning rate schedule.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m \u001b[33;03m    - Training visualization\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and set up environment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enforce GPU-only execution\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA GPU is required to run this notebook. Please run on a GPU-enabled machine.\")\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Add the src directory to Python path for importing modules\n",
    "import pathlib\n",
    "notebook_dir = pathlib.Path().absolute()\n",
    "src_path = notebook_dir.parent.parent / 'src'  # Go up two levels to reach src\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "print(f\"Added to Python path: {src_path}\")\n",
    "\n",
    "# Import your ring attractor modules with correct paths\n",
    "from hd_ring_attractor.models.models import RingAttractorNetwork\n",
    "from hd_ring_attractor.training.enhanced_training import AdamCosineTrainer, create_training_config, train_ring_attractor_with_adam_cosine\n",
    "from hd_ring_attractor.training.training import train_model  # Original training for comparison\n",
    "from hd_ring_attractor.utils.utils import generate_trajectory, angle_to_input, compute_error\n",
    "\n",
    "print(\"Successfully imported all ring attractor modules\")\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "print(f\"All modules imported successfully\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all imports to verify everything is working\n",
    "print(\"Testing all imports...\")\n",
    "\n",
    "try:\n",
    "    # Test basic PyTorch functionality\n",
    "    import torch\n",
    "    test_tensor = torch.randn(2, 3, device=device)\n",
    "    print(\"✓ PyTorch working on GPU\")\n",
    "    \n",
    "    # Test ring attractor modules\n",
    "    from hd_ring_attractor.models.models import RingAttractorNetwork\n",
    "    print(\"✓ RingAttractorNetwork imported\")\n",
    "    \n",
    "    from hd_ring_attractor.training.enhanced_training import AdamCosineTrainer, create_training_config\n",
    "    print(\"✓ Enhanced training system imported\")\n",
    "    \n",
    "    from hd_ring_attractor.training.training import train_model\n",
    "    print(\"✓ Original training imported\")\n",
    "    \n",
    "    from hd_ring_attractor.utils.utils import generate_trajectory, angle_to_input, compute_error\n",
    "    print(\"✓ Utilities imported\")\n",
    "    \n",
    "    # Test creating a small model on GPU\n",
    "    test_model = RingAttractorNetwork(n_exc=8, n_inh=2, dt=0.01, device=device)\n",
    "    test_model = test_model.to(device)\n",
    "    print(\"✓ Model creation working on GPU\")\n",
    "    \n",
    "    # Test utility functions with device\n",
    "    test_angles, _ = generate_trajectory(10, dt=0.1, device=device)\n",
    "    test_inputs = angle_to_input(test_angles, device=device)\n",
    "    print(\"✓ Utility functions working with GPU\")\n",
    "    \n",
    "    print(\"\\n✅ All imports and basic functionality tests passed!\")\n",
    "    print(f\"Running on device: {device}\")\n",
    "    \n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import error: {e}\")\n",
    "    print(\"Please make sure you're running this notebook from the correct directory\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Unexpected error: {e}\")\n",
    "    print(\"There might be an issue with the code - please check the error message above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ring attractor network with standard parameters\n",
    "\"\"\"\n",
    "Initialize a ring attractor network for head direction cell modeling.\n",
    "The network consists of excitatory and inhibitory populations arranged in a ring topology.\n",
    "\"\"\"\n",
    "\n",
    "# Network parameters\n",
    "n_exc = 800        # Number of excitatory neurons (head direction cells)\n",
    "n_inh = 200        # Number of inhibitory neurons\n",
    "n_neurons = n_exc  # For backward compatibility with other cells\n",
    "dt = 0.01          # Time step (seconds)\n",
    "tau_e = 0.02       # Excitatory time constant\n",
    "tau_i = 0.005      # Inhibitory time constant\n",
    "\n",
    "# Create the model with proper device handling\n",
    "model = RingAttractorNetwork(\n",
    "    n_exc=n_exc,\n",
    "    n_inh=n_inh,\n",
    "    dt=dt,\n",
    "    tau_e=tau_e,\n",
    "    tau_i=tau_i,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Move model to device and reset state to ensure everything is on the correct device\n",
    "model = model.to(device)\n",
    "model.reset_state()\n",
    "\n",
    "print(\"Ring Attractor Network Initialized\")\n",
    "print(f\"Excitatory neurons: {n_exc}\")\n",
    "print(f\"Inhibitory neurons: {n_inh}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "print(f\"State device: {model.r_e.device if hasattr(model, 'r_e') and model.r_e is not None else 'Not initialized'}\")\n",
    "\n",
    "# Display initial parameters\n",
    "print(\"\\nInitial Network Parameters\")\n",
    "print(f\"g_ee (E→E gain): {model.g_ee.item():.3f}\")\n",
    "print(f\"g_ei (E→I gain): {model.g_ei.item():.3f}\") \n",
    "print(f\"g_ie (I→E gain): {model.g_ie.item():.3f}\")\n",
    "print(f\"noise_rate_e: {model.noise_rate_e.item():.3f}\")\n",
    "print(f\"noise_rate_i: {model.noise_rate_i.item():.3f}\")\n",
    "\n",
    "# Display connectivity matrix shapes (now fixed!)\n",
    "print(f\"\\nConnectivity matrices (corrected dimensions):\")\n",
    "print(f\"W_EI shape: {model.W_EI.shape} (E→I weights, used as transpose)\")\n",
    "print(f\"W_IE shape: {model.W_IE.shape} (I→E weights, used as transpose)\")\n",
    "\n",
    "# Test model forward pass to ensure device compatibility\n",
    "print(\"\\nDevice Compatibility Test\")\n",
    "test_input = torch.randn(n_exc, device=device) * 0.1\n",
    "try:\n",
    "    test_output = model(test_input)\n",
    "    print(f\"Forward pass successful\")\n",
    "    print(f\"Input device: {test_input.device}\")\n",
    "    print(f\"Output device: {test_output.device}\")\n",
    "    print(f\"All tensors on same device: {test_input.device == test_output.device}\")\n",
    "    print(f\"Matrix operations working correctly - network ready for training!\")\n",
    "except Exception as e:\n",
    "    print(f\"Device compatibility issue: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quick test to verify the fix works\n",
    "\"\"\"\n",
    "Test that the in-place operation error has been fixed.\n",
    "This will run a minimal training example to confirm the gradient computation works.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Testing the In-Place Operation Fix\")\n",
    "\n",
    "# Create a small test model\n",
    "test_model = RingAttractorNetwork(\n",
    "    n_exc=800,  # Small network for quick testing\n",
    "    n_inh=200,\n",
    "    dt=0.01,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Move to device and reset state\n",
    "test_model = test_model.to(device)\n",
    "test_model.reset_state()\n",
    "\n",
    "# Create simple test data\n",
    "test_input = torch.randn(800, device=device) * 0.1\n",
    "test_target = torch.randn(800, device=device) * 0.1\n",
    "\n",
    "print(f\"✓ Test model created on device: {next(test_model.parameters()).device}\")\n",
    "\n",
    "# Test forward pass\n",
    "try:\n",
    "    output = test_model(test_input, steps=1)\n",
    "    print(f\"✓ Forward pass successful, output shape: {output.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Forward pass failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Test backward pass (this is where the error was occurring)\n",
    "try:\n",
    "    # Simple loss calculation\n",
    "    loss = torch.nn.functional.mse_loss(output, test_target)\n",
    "    print(f\"✓ Loss calculation successful: {loss.item():.6f}\")\n",
    "    \n",
    "    # Backward pass - this is where the in-place operation error was happening\n",
    "    loss.backward()\n",
    "    print(\"✓ Backward pass successful - gradient computation works!\")\n",
    "    \n",
    "    # Check that gradients exist\n",
    "    total_grad_norm = 0\n",
    "    param_count = 0\n",
    "    for param in test_model.parameters():\n",
    "        if param.grad is not None:\n",
    "            total_grad_norm += param.grad.norm().item()\n",
    "            param_count += 1\n",
    "    \n",
    "    print(f\"Gradients computed for {param_count} parameters\")\n",
    "    print(f\"Total gradient norm: {total_grad_norm:.6f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Backward pass failed: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nSUCCESS: The in-place operation error has been fixed!\")\n",
    "print(\"The enhanced training system should now work correctly.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Visualize Cosine Annealing Learning Rate Schedule\n",
    "\"\"\"\n",
    "Demonstrate how cosine annealing smoothly reduces the learning rate over training epochs.\n",
    "Formula: η_t = η_min + (η_max - η_min) * (1 + cos(πt/T)) / 2\n",
    "\"\"\"\n",
    "\n",
    "def cosine_annealing_schedule(epoch, max_epochs, lr_max, lr_min):\n",
    "    \"\"\"Compute learning rate for given epoch using cosine annealing\"\"\"\n",
    "    return lr_min + (lr_max - lr_min) * (1 + np.cos(np.pi * epoch / max_epochs)) / 2\n",
    "\n",
    "# Parameters for visualization\n",
    "max_epochs = 100\n",
    "lr_max = 1e-3\n",
    "lr_min = 1e-6\n",
    "\n",
    "epochs = np.arange(0, max_epochs)\n",
    "learning_rates = [cosine_annealing_schedule(epoch, max_epochs, lr_max, lr_min) for epoch in epochs]\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Linear scale\n",
    "ax1.plot(epochs, learning_rates, linewidth=3, color='blue')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Learning Rate')\n",
    "ax1.set_title('Cosine Annealing Learning Rate Schedule')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(y=lr_max, color='red', linestyle='--', alpha=0.7, label=f'Initial LR: {lr_max:.1e}')\n",
    "ax1.axhline(y=lr_min, color='green', linestyle='--', alpha=0.7, label=f'Min LR: {lr_min:.1e}')\n",
    "ax1.legend()\n",
    "\n",
    "# Log scale\n",
    "ax2.semilogy(epochs, learning_rates, linewidth=3, color='blue')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Learning Rate (log scale)')\n",
    "ax2.set_title('Cosine Annealing (Log Scale)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=lr_max, color='red', linestyle='--', alpha=0.7, label=f'Initial LR: {lr_max:.1e}')\n",
    "ax2.axhline(y=lr_min, color='green', linestyle='--', alpha=0.7, label=f'Min LR: {lr_min:.1e}')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Cosine annealing provides smooth, gradual learning rate decay\")\n",
    "print(\"Helps with fine-tuning in later epochs while maintaining exploration early on\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different training configurations\n",
    "## 3. Configure Enhanced Training\n",
    "\n",
    "\"\"\"\n",
    "Create different training configurations to demonstrate various training strategies:\n",
    "1. Quick demo - for fast testing and iteration\n",
    "2. Standard - balanced approach with good monitoring\n",
    "3. Comprehensive - full training with extensive monitoring\n",
    "\"\"\"\n",
    "\n",
    "# Configuration 1: Quick Demo (for fast testing)\n",
    "quick_config = create_training_config(\n",
    "    learning_rate=2e-3,        # Higher learning rate for faster convergence\n",
    "    max_epochs=30,             # Fewer epochs for quick demo\n",
    "    batch_size=16,             # Smaller batch size\n",
    "    n_sequences=200,           # Fewer sequences for speed\n",
    "    sequence_length=50,        # Shorter sequences\n",
    "    log_interval=5,            # More frequent logging\n",
    "    plot_progress=True,        # Enable plotting\n",
    "    early_stopping=True,\n",
    "    patience=10,               # Less patience for quicker stopping\n",
    "    apply_constraints=True,    # Keep biological constraints\n",
    "    device=device              # Add device parameter\n",
    ")\n",
    "\n",
    "# Configuration 2: Standard Training\n",
    "standard_config = create_training_config(\n",
    "    learning_rate=1e-3,        # Standard learning rate\n",
    "    max_epochs=100,            # Standard number of epochs\n",
    "    batch_size=32,             # Standard batch size\n",
    "    n_sequences=1000,          # Good amount of data\n",
    "    sequence_length=100,       # Standard sequence length\n",
    "    log_interval=10,           # Regular logging\n",
    "    plot_progress=True,        # Enable plotting\n",
    "    early_stopping=True,\n",
    "    patience=20,               # Standard patience\n",
    "    weight_decay=1e-4,         # L2 regularization\n",
    "    apply_constraints=True,    # Biological constraints\n",
    "    device=device              # Add device parameter\n",
    ")\n",
    "\n",
    "# Configuration 3: Comprehensive Training\n",
    "comprehensive_config = create_training_config(\n",
    "    learning_rate=5e-4,        # Lower learning rate for stability\n",
    "    max_epochs=200,            # More epochs for thorough training\n",
    "    batch_size=64,             # Larger batch size\n",
    "    n_sequences=2000,          # More training data\n",
    "    sequence_length=150,       # Longer sequences\n",
    "    log_interval=20,           # Less frequent logging\n",
    "    plot_progress=True,        # Enable plotting\n",
    "    early_stopping=True,\n",
    "    patience=40,               # More patience\n",
    "    weight_decay=5e-5,         # Light regularization\n",
    "    min_lr=1e-7,              # Lower minimum learning rate\n",
    "    apply_constraints=True,    # Biological constraints\n",
    "    clip_gradients=True,       # Gradient clipping\n",
    "    max_grad_norm=0.5,         # Stricter gradient clipping\n",
    "    device=device              # Add device parameter\n",
    ")\n",
    "\n",
    "print(\"Training Configurations Created\")\n",
    "print(\"\\n1. Quick Demo Configuration:\")\n",
    "for key, value in quick_config.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(\"\\n2. Standard Configuration:\")\n",
    "for key, value in standard_config.items():\n",
    "    if key in ['learning_rate', 'max_epochs', 'batch_size', 'n_sequences']:\n",
    "        print(f\"   {key}: {value}\")\n",
    "\n",
    "print(\"\\n3. Comprehensive Configuration:\")\n",
    "for key, value in comprehensive_config.items():\n",
    "    if key in ['learning_rate', 'max_epochs', 'batch_size', 'n_sequences']:\n",
    "        print(f\"   {key}: {value}\")\n",
    "\n",
    "print(\"\\nAll configurations ready for training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with enhanced training system (Quick Demo)\n",
    "### 4. Run Enhanced Training (Quick Demo)\n",
    "\n",
    "#Let's start with a quick demo to see the enhanced training system in action.\n",
    "\"\"\"\n",
    "Run a quick demonstration of the enhanced training system.\n",
    "This will show:\n",
    "- Adam optimizer with cosine annealing\n",
    "- Biological constraints enforcement\n",
    "- Real-time monitoring of parameters\n",
    "- Training progress visualization\n",
    "\"\"\"\n",
    "\n",
    "print(\"Starting Quick Demo Training\")\n",
    "\n",
    "\n",
    "# Create a fresh model for training with proper device handling\n",
    "demo_model = RingAttractorNetwork(\n",
    "    n_exc=n_exc,\n",
    "    n_inh=n_inh,\n",
    "    dt=dt,\n",
    "    tau_e=tau_e,\n",
    "    tau_i=tau_i,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Ensure the model is properly moved to device\n",
    "demo_model = demo_model.to(device)\n",
    "demo_model.reset_state()\n",
    "\n",
    "print(f\"✓ Training model created on device: {next(demo_model.parameters()).device}\")\n",
    "\n",
    "# Run enhanced training (with error handling for the fixes)\n",
    "try:\n",
    "    trained_model, history, trainer = train_ring_attractor_with_adam_cosine(\n",
    "        model=demo_model,\n",
    "        config=quick_config\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Training failed with error: {e}\")\n",
    "    print(\"This usually means you need to restart the Jupyter kernel to reload the fixed model code.\")\n",
    "    print(\"Please: Kernel → Restart Kernel, then re-run all cells from the beginning.\")\n",
    "    raise\n",
    "\n",
    "print(\"✓ Quick demo training completed!\")\n",
    "print(f\"✓ Final training loss: {history['train_loss'][-1]:.6f}\")\n",
    "print(f\"✓ Final validation loss: {history['val_loss'][-1]:.6f}\")\n",
    "print(f\"✓ Training epochs completed: {len(history['epoch'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze training results in detail, including parameter evolution and performance metrics.\n",
    "\"\"\"\n",
    "Examine the training results to understand:\n",
    "1. How parameters evolved during training\n",
    "2. Learning rate schedule effectiveness\n",
    "3. Gradient behavior and stability\n",
    "4. Biological constraint enforcement\n",
    "\"\"\"\n",
    "\n",
    "# Check if training has been completed\n",
    "if 'trainer' not in locals() or 'history' not in locals():\n",
    "    print(\"Please run cell 8 (Quick Demo Training) first to generate training results!\")\n",
    "else:\n",
    "    # Display parameter evolution\n",
    "    print(\"Parameter Evolution Analysis\")\n",
    "    print(f\"Initial → Final Parameters:\")\n",
    "    print(f\"g_ee: {trainer.param_history['g_ee'][0]:.3f} → {trainer.param_history['g_ee'][-1]:.3f}\")\n",
    "    print(f\"g_ei: {trainer.param_history['g_ei'][0]:.3f} → {trainer.param_history['g_ei'][-1]:.3f}\")\n",
    "    print(f\"g_ie: {trainer.param_history['g_ie'][0]:.3f} → {trainer.param_history['g_ie'][-1]:.3f}\")\n",
    "    print(f\"noise_rate_e: {trainer.param_history['noise_rate_e'][0]:.3f} → {trainer.param_history['noise_rate_e'][-1]:.3f}\")\n",
    "    print(f\"noise_rate_i: {trainer.param_history['noise_rate_i'][0]:.3f} → {trainer.param_history['noise_rate_i'][-1]:.3f}\")\n",
    "\n",
    "    # Learning rate analysis\n",
    "    print(f\"\\nLearning Rate Schedule Analysis\")\n",
    "    print(f\"Initial learning rate: {history['learning_rate'][0]:.2e}\")\n",
    "    print(f\"Final learning rate: {history['learning_rate'][-1]:.2e}\")\n",
    "    print(f\"Minimum learning rate reached: {min(history['learning_rate']):.2e}\")\n",
    "    print(f\"Learning rate reduction factor: {history['learning_rate'][0] / history['learning_rate'][-1]:.1f}x\")\n",
    "\n",
    "    # Training efficiency\n",
    "    print(f\"\\nTraining Efficiency\")\n",
    "    if history['time_per_epoch']:\n",
    "        avg_time = np.mean(history['time_per_epoch'])\n",
    "        total_time = sum(history['time_per_epoch'])\n",
    "        print(f\"Average time per epoch: {avg_time:.2f} seconds\")\n",
    "        print(f\"Total training time: {total_time:.1f} seconds\")\n",
    "\n",
    "    # Loss improvement\n",
    "    initial_loss = history['train_loss'][0]\n",
    "    final_loss = history['train_loss'][-1]\n",
    "    improvement = (initial_loss - final_loss) / initial_loss * 100\n",
    "    print(f\"Training loss improvement: {improvement:.1f}%\")\n",
    "\n",
    "    # Gradient analysis\n",
    "    print(f\"\\nGradient Analysis\")\n",
    "    avg_grad_norm = np.mean(history['gradient_norm'])\n",
    "    max_grad_norm = max(history['gradient_norm'])\n",
    "    print(f\"Average gradient norm: {avg_grad_norm:.4f}\")\n",
    "    print(f\"Maximum gradient norm: {max_grad_norm:.4f}\")\n",
    "    print(f\"Gradient stability: {'Good' if max_grad_norm < 2.0 else 'Check for instability'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Test Trained Model Performance with Model Resizing\n",
    "\n",
    "# Define model resizing and head direction tracking test functions\n",
    "\"\"\"\n",
    "First define the model resizing function to handle tensor size mismatches,\n",
    "then create head direction tracking test functions.\n",
    "\"\"\"\n",
    "\n",
    "def resize_trained_model(model, new_n_exc, new_n_inh):\n",
    "    \"\"\"\n",
    "    Resize a trained model to new network dimensions while preserving \n",
    "    as much of the learned parameters as possible.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RingAttractorNetwork\n",
    "        new_n_exc: New number of excitatory neurons\n",
    "        new_n_inh: New number of inhibitory neurons\n",
    "        \n",
    "    Returns:\n",
    "        Resized model with updated architecture\n",
    "    \"\"\"\n",
    "    print(f\"Resizing model from ({model.n_exc}, {model.n_inh}) to ({new_n_exc}, {new_n_inh})\")\n",
    "    \n",
    "    # Update basic parameters\n",
    "    model.n_exc = new_n_exc\n",
    "    model.n_inh = new_n_inh\n",
    "    \n",
    "    # Update preferred directions for excitatory neurons\n",
    "    new_preferred_dirs = torch.linspace(0, 2*np.pi, new_n_exc, endpoint=False)\n",
    "    model.register_buffer('preferred_dirs', new_preferred_dirs)\n",
    "    \n",
    "    # Resize weight matrices by intelligent replication\n",
    "    old_n_exc = model.W_EI.shape[1]  # Current excitatory size\n",
    "    old_n_inh = model.W_IE.shape[1]  # Current inhibitory size\n",
    "    \n",
    "    if new_n_exc != old_n_exc:\n",
    "        # Resize W_EI (E→I connections)\n",
    "        # Replicate pattern intelligently\n",
    "        repeat_factor = new_n_exc // old_n_exc\n",
    "        remainder = new_n_exc % old_n_exc\n",
    "        \n",
    "        W_EI_new = model.W_EI.repeat(1, repeat_factor)\n",
    "        if remainder > 0:\n",
    "            W_EI_new = torch.cat([W_EI_new, model.W_EI[:, :remainder]], dim=1)\n",
    "        model.W_EI = nn.Parameter(W_EI_new)\n",
    "        \n",
    "        # Resize W_IE (I→E connections)  \n",
    "        W_IE_new = model.W_IE.repeat(repeat_factor, 1)\n",
    "        if remainder > 0:\n",
    "            W_IE_new = torch.cat([W_IE_new, model.W_IE[:remainder, :]], dim=0)\n",
    "        model.W_IE = nn.Parameter(W_IE_new)\n",
    "    \n",
    "    if new_n_inh != old_n_inh:\n",
    "        # Resize inhibitory dimensions\n",
    "        repeat_factor_inh = new_n_inh // old_n_inh\n",
    "        remainder_inh = new_n_inh % old_n_inh\n",
    "        \n",
    "        # Update W_EI (add more inhibitory neurons)\n",
    "        W_EI_new = model.W_EI.repeat(repeat_factor_inh, 1)\n",
    "        if remainder_inh > 0:\n",
    "            W_EI_new = torch.cat([W_EI_new, model.W_EI[:remainder_inh, :]], dim=0)\n",
    "        model.W_EI = nn.Parameter(W_EI_new)\n",
    "        \n",
    "        # Update W_IE (add more inhibitory neurons)\n",
    "        W_IE_new = model.W_IE.repeat(1, repeat_factor_inh)\n",
    "        if remainder_inh > 0:\n",
    "            W_IE_new = torch.cat([W_IE_new, model.W_IE[:, :remainder_inh]], dim=1)\n",
    "        model.W_IE = nn.Parameter(W_IE_new)\n",
    "    \n",
    "    # Reset states to match new dimensions\n",
    "    model.reset_state()\n",
    "    \n",
    "    print(f\"✓ Model resized successfully to ({new_n_exc}, {new_n_inh})\")\n",
    "    print(f\"✓ W_EI shape: {model.W_EI.shape}\")\n",
    "    print(f\"✓ W_IE shape: {model.W_IE.shape}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_static_direction_test():\n",
    "    \"\"\"\n",
    "    Generate test data for static head direction (should maintain bump).\n",
    "    \"\"\"\n",
    "    dt = 0.05\n",
    "    duration = 3.0\n",
    "    n_steps = int(duration / dt)\n",
    "    \n",
    "    # Fixed direction at 90 degrees\n",
    "    direction = np.pi / 2\n",
    "    head_directions = np.full(n_steps, direction)\n",
    "    \n",
    "    return head_directions, \"Maintain bump at fixed direction\"\n",
    "\n",
    "\n",
    "def generate_slow_turn_test():\n",
    "    \"\"\"\n",
    "    Generate test data for a slow head direction turn.\n",
    "    \"\"\"\n",
    "    dt = 0.05\n",
    "    duration = 4.0\n",
    "    n_steps = int(duration / dt)\n",
    "    \n",
    "    # Slow turn from 0 to π radians\n",
    "    start_dir = 0.0\n",
    "    end_dir = np.pi\n",
    "    head_directions = np.linspace(start_dir, end_dir, n_steps)\n",
    "    \n",
    "    return head_directions, \"Slow 180° turn over 4s\"\n",
    "\n",
    "\n",
    "def generate_fast_turn_test():\n",
    "    \"\"\"\n",
    "    Generate test data for a fast head direction turn.\n",
    "    \"\"\"\n",
    "    dt = 0.05\n",
    "    duration = 1.0\n",
    "    n_steps = int(duration / dt)\n",
    "    \n",
    "    # Fast turn from 0 to π radians\n",
    "    start_dir = 0.0\n",
    "    end_dir = np.pi\n",
    "    head_directions = np.linspace(start_dir, end_dir, n_steps)\n",
    "    \n",
    "    return head_directions, \"Fast 180° turn over 1s\"\n",
    "\n",
    "\n",
    "def generate_oscillation_test():\n",
    "    \"\"\"\n",
    "    Generate test data for head direction oscillation.\n",
    "    \"\"\"\n",
    "    dt = 0.05\n",
    "    duration = 6.0\n",
    "    n_steps = int(duration / dt)\n",
    "    \n",
    "    # Oscillation around central direction\n",
    "    t = np.arange(n_steps) * dt\n",
    "    central_dir = np.pi / 2\n",
    "    amplitude = np.pi / 4\n",
    "    frequency = 0.5\n",
    "    head_directions = central_dir + amplitude * np.sin(2 * np.pi * frequency * t)\n",
    "    \n",
    "    return head_directions, \"Oscillation ±45° around 90°\"\n",
    "\n",
    "\n",
    "def generate_random_walk_test():\n",
    "    \"\"\"\n",
    "    Generate test data for random walk head direction.\n",
    "    \"\"\"\n",
    "    dt = 0.05\n",
    "    duration = 5.0\n",
    "    n_steps = int(duration / dt)\n",
    "    \n",
    "    # Random walk with drift\n",
    "    head_directions = np.zeros(n_steps)\n",
    "    head_directions[0] = 0.0\n",
    "    \n",
    "    for i in range(1, n_steps):\n",
    "        # Small random changes with occasional larger turns\n",
    "        if np.random.random() < 0.1:  # 10% chance of larger turn\n",
    "            change = np.random.normal(0, 0.5)\n",
    "        else:\n",
    "            change = np.random.normal(0, 0.1)\n",
    "        head_directions[i] = head_directions[i-1] + change\n",
    "    \n",
    "    # Keep in [0, 2π] range\n",
    "    head_directions = np.mod(head_directions, 2*np.pi)\n",
    "    \n",
    "    return head_directions, \"Random walk with occasional turns\"\n",
    "\n",
    "\n",
    "def run_tracking_simulation(model, head_directions):\n",
    "    \"\"\"\n",
    "    Run head direction tracking simulation and return results.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RingAttractorNetwork\n",
    "        head_directions: Array of head directions to track\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with simulation results and metrics\n",
    "    \"\"\"\n",
    "    dt = 0.05\n",
    "    n_steps = len(head_directions)\n",
    "    \n",
    "    # Storage for results\n",
    "    decoded_directions = np.zeros(n_steps)\n",
    "    tracking_errors = np.zeros(n_steps)\n",
    "    bump_amplitudes = np.zeros(n_steps)\n",
    "    \n",
    "    # Reset model state\n",
    "    model.eval()\n",
    "    model.reset_state()\n",
    "    \n",
    "    # Run simulation\n",
    "    with torch.no_grad():\n",
    "        for step in range(n_steps):\n",
    "            # Create input for current direction\n",
    "            input_pattern = angle_to_input(\n",
    "                torch.tensor(head_directions[step]),\n",
    "                n_exc=model.n_exc,\n",
    "                input_strength=1.0,\n",
    "                input_width=0.3,\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            # Run network step\n",
    "            activity = model(input_pattern.to(model.device), steps=1)\n",
    "            \n",
    "            # Decode direction and compute error\n",
    "            decoded_dir = model.decode_angle(activity).cpu().numpy()\n",
    "            decoded_directions[step] = decoded_dir\n",
    "            \n",
    "            # Compute tracking error (shortest angular distance)\n",
    "            error = np.abs(decoded_dir - head_directions[step])\n",
    "            error = min(error, 2*np.pi - error)  # Handle wraparound\n",
    "            tracking_errors[step] = error\n",
    "            \n",
    "            # Compute bump amplitude\n",
    "            bump_amplitudes[step] = torch.max(activity).cpu().numpy()\n",
    "    \n",
    "    # Compute metrics\n",
    "    mean_error = np.mean(tracking_errors)\n",
    "    max_error = np.max(tracking_errors)\n",
    "    \n",
    "    # Tracking accuracy (percentage within 30 degrees)\n",
    "    accuracy_threshold = np.radians(30)\n",
    "    tracking_accuracy = np.mean(tracking_errors < accuracy_threshold) * 100\n",
    "    \n",
    "    # Bump stability (lower variance = more stable)\n",
    "    bump_stability = 1.0 / (1.0 + np.var(bump_amplitudes))\n",
    "    \n",
    "    return {\n",
    "        'head_directions': head_directions,\n",
    "        'decoded_directions': decoded_directions,\n",
    "        'tracking_errors': tracking_errors,\n",
    "        'bump_amplitudes': bump_amplitudes,\n",
    "        'mean_error': mean_error,\n",
    "        'max_error': max_error,\n",
    "        'tracking_accuracy': tracking_accuracy,\n",
    "        'bump_stability': bump_stability\n",
    "    }\n",
    "\n",
    "print(\"Head direction tracking test functions defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model with automatic resizing\n",
    "# Check if training has been completed\n",
    "if 'trained_model' not in locals():\n",
    "    print(\"Please run cell 7 (Quick Demo Training) first to generate a trained model!\")\n",
    "else:\n",
    "    print(\"Testing Trained Model Performance\")\n",
    "    \n",
    "    # Check if model needs resizing to match current network parameters\n",
    "    if trained_model.n_exc != n_exc or trained_model.n_inh != n_inh:\n",
    "        print(f\" Model size mismatch detected:\")\n",
    "        print(f\"   • Trained model: ({trained_model.n_exc}, {trained_model.n_inh})\")\n",
    "        print(f\"   • Current parameters: ({n_exc}, {n_inh})\")\n",
    "        print(f\"   • Resizing model to match current parameters...\")\n",
    "        \n",
    "        # Resize the trained model to match current network parameters\n",
    "        trained_model = resize_trained_model(trained_model, n_exc, n_inh)\n",
    "        print(\"✓ Model resized successfully!\")\n",
    "    \n",
    "    # Verify the model exists and is trained\n",
    "    try:\n",
    "        # Check if model has been trained (parameters should have changed from initialization)\n",
    "        model_param_sum = sum(p.sum().item() for p in trained_model.parameters())\n",
    "        print(f\"✓ Model loaded with parameter sum: {model_param_sum:.3f}\")\n",
    "        print(f\"✓ Model device: {next(trained_model.parameters()).device}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Model verification failed: {e}\")\n",
    "        print(\"Please re-run the training cell first.\")\n",
    "    else:\n",
    "        # Generate a test trajectory\n",
    "        test_length = 200\n",
    "        test_angles, test_velocities = generate_trajectory(test_length, dt=0.1, device=device)\n",
    "        test_inputs = angle_to_input(test_angles, n_exc=trained_model.n_exc, device=device)  # 🔧 FIX: Specify correct network size!\n",
    "\n",
    "        # Convert to tensors and move to device\n",
    "        test_inputs_tensor = torch.tensor(test_inputs, dtype=torch.float32).to(device)\n",
    "        test_angles_tensor = torch.tensor(test_angles, dtype=torch.float32).to(device)\n",
    "\n",
    "        print(f\"✓ Generated test trajectory: {test_length} steps\")\n",
    "        print(f\"✓ Test data on device: {test_inputs_tensor.device}\")\n",
    "\n",
    "        # Set model to evaluation mode and reset state\n",
    "        trained_model.eval()\n",
    "        trained_model.reset_state()\n",
    "        \n",
    "        # Run the trained model with proper error handling\n",
    "        predicted_angles = []\n",
    "        \n",
    "        print(\"Running model inference...\")\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                for t in range(test_length):\n",
    "                    # Get input for this timestep\n",
    "                    input_t = test_inputs_tensor[t, :].unsqueeze(0)  # Add batch dimension\n",
    "                    \n",
    "                    # Forward pass through the model\n",
    "                    # The model expects: (batch_size, input_dim) and returns activity\n",
    "                    activity = trained_model(input_t, steps=1)\n",
    "                    \n",
    "                    # Decode the angle from the activity\n",
    "                    predicted_angle = trained_model.decode_angle(activity)\n",
    "                    predicted_angles.append(predicted_angle.cpu().numpy().item())\n",
    "\n",
    "            predicted_angles = np.array(predicted_angles)\n",
    "            print(f\"✓ Model inference completed: {len(predicted_angles)} predictions\")\n",
    "\n",
    "            # Compute tracking error\n",
    "            tracking_errors = []\n",
    "            for i in range(len(test_angles)):\n",
    "                error = compute_error(torch.tensor([predicted_angles[i]]), torch.tensor([test_angles[i]]))\n",
    "                tracking_errors.append(error.item())\n",
    "\n",
    "            # Display performance metrics\n",
    "            print(\"\\nModel Performance on Test Trajectory\")\n",
    "            print(f\"Mean tracking error: {np.mean(tracking_errors):.4f} radians\")\n",
    "            print(f\"RMS tracking error: {np.sqrt(np.mean(np.array(tracking_errors)**2)):.4f} radians\")\n",
    "            print(f\"Max tracking error: {np.max(tracking_errors):.4f} radians\")\n",
    "            print(f\"Mean error in degrees: {np.mean(tracking_errors) * 180 / np.pi:.2f}°\")\n",
    "\n",
    "            # Visualize tracking performance\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "            # Plot 1: Trajectory tracking\n",
    "            time_points = np.arange(test_length) * 0.1\n",
    "            axes[0, 0].plot(time_points, test_angles, 'b-', linewidth=2, label='True Angle', alpha=0.8)\n",
    "            axes[0, 0].plot(time_points, predicted_angles, 'r--', linewidth=2, label='Predicted Angle', alpha=0.8)\n",
    "            axes[0, 0].set_xlabel('Time (s)')\n",
    "            axes[0, 0].set_ylabel('Head Direction (radians)')\n",
    "            axes[0, 0].set_title('Head Direction Tracking')\n",
    "            axes[0, 0].legend()\n",
    "            axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "            # Plot 2: Tracking error over time\n",
    "            axes[0, 1].plot(time_points, tracking_errors, 'g-', linewidth=2)\n",
    "            axes[0, 1].set_xlabel('Time (s)')\n",
    "            axes[0, 1].set_ylabel('Tracking Error (radians)')\n",
    "            axes[0, 1].set_title('Tracking Error Over Time')\n",
    "            axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "            # Plot 3: Error distribution\n",
    "            axes[1, 0].hist(tracking_errors, bins=20, alpha=0.7, color='orange', edgecolor='black')\n",
    "            axes[1, 0].set_xlabel('Tracking Error (radians)')\n",
    "            axes[1, 0].set_ylabel('Frequency')\n",
    "            axes[1, 0].set_title('Error Distribution')\n",
    "            axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "            # Plot 4: Scatter plot of true vs predicted\n",
    "            axes[1, 1].scatter(test_angles, predicted_angles, alpha=0.6, s=20)\n",
    "            axes[1, 1].plot([0, 2*np.pi], [0, 2*np.pi], 'r--', linewidth=2, label='Perfect Tracking')\n",
    "            axes[1, 1].set_xlabel('True Angle (radians)')\n",
    "            axes[1, 1].set_ylabel('Predicted Angle (radians)')\n",
    "            axes[1, 1].set_title('True vs Predicted Angles')\n",
    "            axes[1, 1].legend()\n",
    "            axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            print(\"✓ Model performance evaluation completed successfully!\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during model inference: {e}\")\n",
    "            print(f\"Error type: {type(e).__name__}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            print(\"\\nThis error suggests an issue with the model's forward pass during inference.\")\n",
    "            print(\"Try rerunning the training cell and ensure it completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enhanced Tracking Simulation with Improved Parameters\n",
    "\n",
    "# Create an enhanced version of the tracking simulation with optimizations for better accuracy\n",
    "\"\"\"\n",
    "This cell implements several improvements to boost tracking accuracy:\n",
    "1. Reduced noise levels during tracking\n",
    "2. Adaptive input strength based on tracking error\n",
    "3. More focused input width for sharper bumps\n",
    "4. Enhanced input baseline strength\n",
    "5. Better bump initialization\n",
    "\"\"\"\n",
    "\n",
    "def run_enhanced_tracking_simulation(model, head_directions):\n",
    "    \"\"\"\n",
    "    Run head direction tracking simulation with ENHANCED parameters for better accuracy.\n",
    "    \n",
    "    Improvements:\n",
    "    - Adaptive input strength based on tracking error\n",
    "    - Reduced noise levels during tracking\n",
    "    - More focused input width for sharper bumps\n",
    "    - Enhanced baseline input strength\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RingAttractorNetwork\n",
    "        head_directions: Array of head directions to track\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with simulation results and metrics\n",
    "    \"\"\"\n",
    "    dt = 0.05\n",
    "    n_steps = len(head_directions)\n",
    "    \n",
    "    # Storage for results\n",
    "    decoded_directions = np.zeros(n_steps)\n",
    "    tracking_errors = np.zeros(n_steps)\n",
    "    bump_amplitudes = np.zeros(n_steps)\n",
    "    neural_activities = np.zeros((n_steps, model.n_exc))\n",
    "    input_strengths_used = np.zeros(n_steps)  # Track adaptive input strength\n",
    "    \n",
    "    # Reset model state\n",
    "    model.eval()\n",
    "    model.reset_state()\n",
    "    \n",
    "    # OPTIMIZATION 1: Temporarily reduce noise for better tracking\n",
    "    original_noise_e = model.noise_rate_e.item()\n",
    "    original_noise_i = model.noise_rate_i.item()\n",
    "    with torch.no_grad():\n",
    "        model.noise_rate_e.data = torch.tensor(0.005, device=model.device)  # Reduced noise\n",
    "        model.noise_rate_i.data = torch.tensor(0.02, device=model.device)   # Reduced noise\n",
    "    \n",
    "    # OPTIMIZATION 2: Enhanced bump initialization\n",
    "    if len(head_directions) > 0:\n",
    "        model.initialize_bump(head_directions[0], width=0.25, amplitude=0.2)  # Stronger, sharper initial bump\n",
    "    \n",
    "    # Run simulation\n",
    "    with torch.no_grad():\n",
    "        for step in range(n_steps):\n",
    "            # OPTIMIZATION 3: Adaptive input strength based on recent tracking performance\n",
    "            if step > 0:\n",
    "                recent_error = tracking_errors[step-1]\n",
    "                if recent_error > np.radians(45):  # 45 degree threshold\n",
    "                    input_strength = 2.5  # Strong boost when tracking poorly\n",
    "                elif recent_error > np.radians(20):  # 20 degree threshold\n",
    "                    input_strength = 1.8  # Moderate boost\n",
    "                else:\n",
    "                    input_strength = 1.5  # Enhanced baseline strength\n",
    "            else:\n",
    "                input_strength = 1.5  # Enhanced initial strength\n",
    "            \n",
    "            input_strengths_used[step] = input_strength\n",
    "            \n",
    "            # OPTIMIZATION 4: More focused input width for sharper bumps\n",
    "            input_width = 0.15  # Much narrower than default 0.3\n",
    "            \n",
    "            # Create enhanced input for current direction\n",
    "            input_pattern = angle_to_input(\n",
    "                torch.tensor(head_directions[step]),\n",
    "                n_exc=model.n_exc,\n",
    "                input_strength=input_strength,\n",
    "                input_width=input_width,\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            # Run network step\n",
    "            activity = model(input_pattern.to(model.device), steps=1)\n",
    "            \n",
    "            # Store results\n",
    "            neural_activities[step] = activity.cpu().numpy()\n",
    "            \n",
    "            # Decode direction and compute error\n",
    "            decoded_dir = model.decode_angle(activity).cpu().numpy()\n",
    "            decoded_directions[step] = decoded_dir\n",
    "            \n",
    "            # Compute tracking error (shortest angular distance)\n",
    "            error = np.abs(decoded_dir - head_directions[step])\n",
    "            error = min(error, 2*np.pi - error)  # Handle wraparound\n",
    "            tracking_errors[step] = error\n",
    "            \n",
    "            # Compute bump amplitude\n",
    "            bump_amplitudes[step] = torch.max(activity).cpu().numpy()\n",
    "    \n",
    "    # Restore original noise levels\n",
    "    with torch.no_grad():\n",
    "        model.noise_rate_e.data = torch.tensor(original_noise_e, device=model.device)\n",
    "        model.noise_rate_i.data = torch.tensor(original_noise_i, device=model.device)\n",
    "    \n",
    "    # Compute enhanced metrics\n",
    "    mean_error = np.mean(tracking_errors)\n",
    "    max_error = np.max(tracking_errors)\n",
    "    \n",
    "    # Multiple accuracy thresholds\n",
    "    accuracy_15deg = np.mean(tracking_errors < np.radians(15)) * 100  # Strict threshold\n",
    "    accuracy_30deg = np.mean(tracking_errors < np.radians(30)) * 100  # Standard threshold\n",
    "    accuracy_45deg = np.mean(tracking_errors < np.radians(45)) * 100  # Lenient threshold\n",
    "    \n",
    "    # Bump stability and consistency\n",
    "    bump_stability = 1.0 / (1.0 + np.var(bump_amplitudes))\n",
    "    bump_consistency = np.mean(bump_amplitudes > 0.05)  # Percentage of time with detectable bump\n",
    "    \n",
    "    # Adaptive input usage statistics\n",
    "    avg_input_strength = np.mean(input_strengths_used)\n",
    "    input_adaptations = np.sum(np.diff(input_strengths_used) != 0)\n",
    "    \n",
    "    return {\n",
    "        'head_directions': head_directions,\n",
    "        'decoded_directions': decoded_directions,\n",
    "        'tracking_errors': tracking_errors,\n",
    "        'bump_amplitudes': bump_amplitudes,\n",
    "        'neural_activities': neural_activities,\n",
    "        'input_strengths_used': input_strengths_used,\n",
    "        'mean_error': mean_error,\n",
    "        'max_error': max_error,\n",
    "        'tracking_accuracy': accuracy_30deg,  # Standard metric\n",
    "        'accuracy_15deg': accuracy_15deg,     # Strict accuracy\n",
    "        'accuracy_45deg': accuracy_45deg,     # Lenient accuracy\n",
    "        'bump_stability': bump_stability,\n",
    "        'bump_consistency': bump_consistency,\n",
    "        'avg_input_strength': avg_input_strength,\n",
    "        'input_adaptations': input_adaptations\n",
    "    }\n",
    "\n",
    "\n",
    "# Replace the original tracking function with the enhanced version\n",
    "# This allows us to compare performance\n",
    "print(\"✓ Enhanced tracking simulation function defined\")\n",
    "print(\"Improvements include:\")\n",
    "print(\"  • Reduced noise levels during tracking\")\n",
    "print(\"  • Adaptive input strength based on tracking error\")\n",
    "print(\"  • More focused input width (0.15 vs 0.3)\")\n",
    "print(\"  • Enhanced baseline input strength (1.5 vs 1.0)\")\n",
    "print(\"  • Better bump initialization\")\n",
    "print(\"  • Multiple accuracy thresholds for detailed assessment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Head Direction Tracking Performance Evaluation\n",
    "\n",
    "# Run head direction tracking evaluation with trained parameters\n",
    "\"\"\"\n",
    "Evaluate head direction tracking performance using the trained parameters.\n",
    "Tests how well the network maintains and tracks head direction with the \n",
    "optimized parameters found during training.\n",
    "\"\"\"\n",
    "\n",
    "# Check if training has been completed\n",
    "if 'trained_model' not in locals() or 'trainer' not in locals():\n",
    "    print(\"run the training cells first to generate a trained model\")\n",
    "    print(\"   Specifically, run Cell 7 (Quick Demo Training) to get the trained_model\")\n",
    "else:\n",
    "    print(\"Head Direction Tracking Performance with Trained Parameters\")\n",
    "    \n",
    "    # Display the trained parameters being used\n",
    "    print(\"Using trained parameters:\")\n",
    "    print(f\"  • σ_EE (connection width): {trained_model.sigma_ee.item():.4f}\")\n",
    "    print(f\"  • g_ee (E→E gain): {trained_model.g_ee.item():.4f}\")\n",
    "    print(f\"  • g_ei (E→I gain): {trained_model.g_ei.item():.4f}\")\n",
    "    print(f\"  • g_ie (I→E gain): {trained_model.g_ie.item():.4f}\")\n",
    "    print(f\"  • Noise rate E: {trained_model.noise_rate_e.item():.4f}\")\n",
    "    print(f\"  • Noise rate I: {trained_model.noise_rate_i.item():.4f}\")\n",
    "    print(f\"  • Network size: ({trained_model.n_exc}, {trained_model.n_inh}) neurons\")\n",
    "    \n",
    "    # Test different head direction tracking scenarios\n",
    "    scenarios = {\n",
    "        'static_direction': generate_static_direction_test(),\n",
    "        'slow_turn': generate_slow_turn_test(),\n",
    "        'fast_turn': generate_fast_turn_test(),\n",
    "        'oscillation': generate_oscillation_test(),\n",
    "        'random_walk': generate_random_walk_test()\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(\"\\nRunning Head Direction Tracking Tests...\")\n",
    "    \n",
    "    for scenario_name, (head_directions, description) in scenarios.items():\n",
    "        print(f\"\\n• Testing {scenario_name}: {description}\")\n",
    "        \n",
    "        # Run tracking simulation\n",
    "        tracking_results = run_tracking_simulation(trained_model, head_directions)\n",
    "        results[scenario_name] = tracking_results\n",
    "        \n",
    "        # Print performance metrics\n",
    "        mean_error = np.degrees(tracking_results['mean_error'])\n",
    "        max_error = np.degrees(tracking_results['max_error'])\n",
    "        tracking_accuracy = tracking_results['tracking_accuracy']\n",
    "        \n",
    "        print(f\"   • Mean tracking error: {mean_error:.1f}°\")\n",
    "        print(f\"   • Max tracking error: {max_error:.1f}°\")\n",
    "        print(f\"   • Tracking accuracy: {tracking_accuracy:.1f}%\")\n",
    "    \n",
    "    print(\"\\n✓ All tracking tests completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. Visualize Head Direction Tracking Results\n",
    "\n",
    "# Create comprehensive visualization of tracking performance\n",
    "\"\"\"\n",
    "Create detailed visualizations showing:\n",
    "1. Direction tracking for each scenario\n",
    "2. Tracking errors over time  \n",
    "3. Bump amplitude evolution\n",
    "4. Summary statistics across scenarios\n",
    "\"\"\"\n",
    "\n",
    "def plot_tracking_performance(results, scenarios):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualization of tracking performance across scenarios.\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"No tracking results available. Please run the tracking evaluation first!\")\n",
    "        return\n",
    "        \n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    fig.suptitle('Head Direction Tracking Performance with Trained Parameters', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    n_scenarios = len(results)\n",
    "    \n",
    "    # Create subplots\n",
    "    gs = fig.add_gridspec(3, n_scenarios, hspace=0.4, wspace=0.3)\n",
    "    \n",
    "    scenario_names = list(results.keys())\n",
    "    \n",
    "    for i, scenario_name in enumerate(scenario_names):\n",
    "        result = results[scenario_name]\n",
    "        description = scenarios[scenario_name][1]\n",
    "        \n",
    "        dt = 0.05\n",
    "        time_points = np.arange(len(result['head_directions'])) * dt\n",
    "        \n",
    "        # Row 1: Direction tracking\n",
    "        ax1 = fig.add_subplot(gs[0, i])\n",
    "        ax1.plot(time_points, np.degrees(result['head_directions']), \n",
    "                'r-', linewidth=2, label='Actual', alpha=0.8)\n",
    "        ax1.plot(time_points, np.degrees(result['decoded_directions']), \n",
    "                'b--', linewidth=2, label='Decoded', alpha=0.8)\n",
    "        ax1.set_title(f'{scenario_name.replace(\"_\", \" \").title()}\\n{description}', fontsize=10)\n",
    "        ax1.set_ylabel('Direction (°)')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        if i == 0:\n",
    "            ax1.legend()\n",
    "        \n",
    "        # Row 2: Tracking error\n",
    "        ax2 = fig.add_subplot(gs[1, i])\n",
    "        ax2.plot(time_points, np.degrees(result['tracking_errors']), \n",
    "                'purple', linewidth=2)\n",
    "        ax2.axhline(y=30, color='red', linestyle='--', alpha=0.5, label='30° threshold')\n",
    "        ax2.set_ylabel('Error (°)')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        if i == 0:\n",
    "            ax2.legend()\n",
    "        \n",
    "        # Row 3: Bump amplitude\n",
    "        ax3 = fig.add_subplot(gs[2, i])\n",
    "        ax3.plot(time_points, result['bump_amplitudes'], \n",
    "                'green', linewidth=2)\n",
    "        ax3.set_xlabel('Time (s)')\n",
    "        ax3.set_ylabel('Bump Amplitude')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_summary_statistics(results):\n",
    "    \"\"\"\n",
    "    Plot summary statistics across all tracking scenarios.\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"No tracking results available. Please run the tracking evaluation first!\")\n",
    "        return\n",
    "        \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig.suptitle('Tracking Performance Summary', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    scenario_names = [name.replace('_', ' ').title() for name in results.keys()]\n",
    "    \n",
    "    # Mean tracking errors\n",
    "    mean_errors = [np.degrees(result['mean_error']) for result in results.values()]\n",
    "    axes[0].bar(scenario_names, mean_errors, color='skyblue', alpha=0.7)\n",
    "    axes[0].set_ylabel('Mean Error (°)')\n",
    "    axes[0].set_title('Mean Tracking Error')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Tracking accuracy\n",
    "    accuracies = [result['tracking_accuracy'] for result in results.values()]\n",
    "    axes[1].bar(scenario_names, accuracies, color='lightgreen', alpha=0.7)\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_title('Tracking Accuracy (<30° error)')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_ylim(0, 100)\n",
    "    \n",
    "    # Bump stability\n",
    "    stabilities = [result['bump_stability'] for result in results.values()]\n",
    "    axes[2].bar(scenario_names, stabilities, color='orange', alpha=0.7)\n",
    "    axes[2].set_ylabel('Stability Index')\n",
    "    axes[2].set_title('Bump Stability')\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Generate the visualizations if results are available\n",
    "if 'results' in locals() and results:\n",
    "    print(\"Creating tracking performance visualizations...\")\n",
    "    \n",
    "    # Main tracking performance plot\n",
    "    plot_tracking_performance(results, scenarios)\n",
    "    \n",
    "    # Summary statistics\n",
    "    plot_summary_statistics(results)\n",
    "    \n",
    "    # Print overall tracking performance summary\n",
    "    print(\"\\nHead Direction Tracking Summary with Trained Parameters:\")\n",
    "    \n",
    "    for scenario, result in results.items():\n",
    "        mean_error_deg = np.degrees(result['mean_error'])\n",
    "        accuracy = result['tracking_accuracy']\n",
    "        stability = result['bump_stability']\n",
    "        scenario_display = scenario.replace('_', ' ').title()\n",
    "        print(f\"   • {scenario_display:15}: {mean_error_deg:4.1f}° error, \"\n",
    "              f\"{accuracy:5.1f}% accuracy, {stability:.3f} stability\")\n",
    "    \n",
    "    # Overall performance assessment\n",
    "    overall_accuracy = np.mean([result['tracking_accuracy'] for result in results.values()])\n",
    "    overall_error = np.mean([np.degrees(result['mean_error']) for result in results.values()])\n",
    "    \n",
    "\n",
    "    print(f\"Overall Performance:\")\n",
    "    print(f\"Average tracking error: {overall_error:.1f}°\")\n",
    "    print(f\"Average accuracy: {overall_accuracy:.1f}%\")\n",
    "    \n",
    "    if overall_accuracy > 85:\n",
    "        print(\"Excellent tracking performance!\")\n",
    "    elif overall_accuracy > 70:\n",
    "        print(\"Good tracking performance\")\n",
    "    else:\n",
    "        print(\"Consider further training or parameter tuning\")\n",
    "        \n",
    "else:\n",
    "    print(\"No tracking results to visualize. Please run the tracking evaluation first!\")\n",
    "    print(\"Run the previous cell (Cell 11) to generate tracking results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9. Focused Head Direction Turn Simulation\n",
    "\n",
    "# Create focused head direction turn simulation showing Gaussian bump evolution\n",
    "\"\"\"\n",
    "Simulate a single head direction turn showing:\n",
    "1. Head starting at a random direction\n",
    "2. Gaussian bump formation at that direction  \n",
    "3. How the bump evolves as the head turns\n",
    "4. Neural activity patterns during the turn\n",
    "\n",
    "This addresses your original request to see the Gaussian bump forming and changing!\n",
    "\"\"\"\n",
    "\n",
    "def simulate_head_direction_turn(model, turn_duration=4.0, turn_amount_deg=180):\n",
    "    \"\"\"\n",
    "    Simulate a head direction turn with the trained model.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RingAttractorNetwork\n",
    "        turn_duration: Duration of turn in seconds\n",
    "        turn_amount_deg: Amount to turn in degrees\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with simulation results\n",
    "    \"\"\"\n",
    "    dt = 0.05\n",
    "    n_steps = int(turn_duration / dt)\n",
    "    \n",
    "    # Random starting direction\n",
    "    start_direction = np.random.uniform(0, 2*np.pi)\n",
    "    turn_amount_rad = np.radians(turn_amount_deg)\n",
    "    \n",
    "    # Create smooth turn trajectory (sigmoid)\n",
    "    t_normalized = np.arange(n_steps) / n_steps\n",
    "    progress = 1 / (1 + np.exp(-8 * (t_normalized - 0.5)))\n",
    "    progress = (progress - progress[0]) / (progress[-1] - progress[0])\n",
    "    \n",
    "    # Generate head directions\n",
    "    head_directions = start_direction + turn_amount_rad * progress\n",
    "    head_directions = np.mod(head_directions, 2*np.pi)\n",
    "    \n",
    "    # Storage for results\n",
    "    neural_activities = np.zeros((n_steps, model.n_exc))\n",
    "    decoded_directions = np.zeros(n_steps)\n",
    "    bump_amplitudes = np.zeros(n_steps)\n",
    "    \n",
    "    # Reset model and initialize with starting direction\n",
    "    model.eval()\n",
    "    model.reset_state()\n",
    "    model.initialize_bump(start_direction, width=0.3, amplitude=0.1)\n",
    "    \n",
    "    # Run simulation\n",
    "    for step in range(n_steps):\n",
    "        # Create input for current direction\n",
    "        input_pattern = angle_to_input(\n",
    "            torch.tensor(head_directions[step]),\n",
    "            n_exc=model.n_exc,\n",
    "            input_strength=1.0,\n",
    "            input_width=0.3,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # Run network step\n",
    "        with torch.no_grad():\n",
    "            activity = model(input_pattern.to(model.device), steps=1)\n",
    "        \n",
    "        # Store results\n",
    "        neural_activities[step] = activity.cpu().numpy()\n",
    "        bump_amplitudes[step] = np.max(activity.cpu().numpy())\n",
    "        decoded_directions[step] = model.decode_angle(activity).cpu().numpy()\n",
    "    \n",
    "    return {\n",
    "        'head_directions': head_directions,\n",
    "        'neural_activities': neural_activities,\n",
    "        'decoded_directions': decoded_directions,\n",
    "        'bump_amplitudes': bump_amplitudes,\n",
    "        'time_points': np.arange(n_steps) * dt,\n",
    "        'start_direction_deg': np.degrees(start_direction),\n",
    "        'turn_amount_deg': turn_amount_deg,\n",
    "        'turn_duration': turn_duration\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_head_direction_turn(sim_results):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualization of a head direction turn.\n",
    "    \"\"\"\n",
    "    # Create figure with polar and cartesian subplots\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    fig.suptitle(f'Head Direction Turn: {sim_results[\"turn_amount_deg\"]:.0f}° over {sim_results[\"turn_duration\"]:.1f}s\\n'\n",
    "                 f'Starting at {sim_results[\"start_direction_deg\"]:.0f}° with Trained Parameters', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Create subplot layout\n",
    "    gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # 1. Polar plot showing neural activity ring (left, spanning 2 rows)\n",
    "    ax_ring = fig.add_subplot(gs[:, 0], projection='polar')\n",
    "    \n",
    "    # Show final neural activity as a polar plot\n",
    "    final_activity = sim_results['neural_activities'][-1]\n",
    "    preferred_dirs = np.linspace(0, 2*np.pi, len(final_activity), endpoint=False)\n",
    "    \n",
    "    ax_ring.plot(preferred_dirs, final_activity, 'b-', linewidth=3, alpha=0.8, label='Network Activity')\n",
    "    ax_ring.plot([sim_results['head_directions'][-1]], [1.1], 'ro', markersize=12, label='Head Direction')\n",
    "    ax_ring.plot([sim_results['decoded_directions'][-1]], [1.05], 'bo', markersize=8, label='Decoded Direction')\n",
    "    ax_ring.set_ylim(0, 1.2)\n",
    "    ax_ring.set_title('Final Neural Activity Ring', fontsize=12, pad=20)\n",
    "    ax_ring.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "    \n",
    "    # 2. Head direction trajectory (top right)\n",
    "    ax_traj = fig.add_subplot(gs[0, 1])\n",
    "    ax_traj.plot(sim_results['time_points'], np.degrees(sim_results['head_directions']), \n",
    "                'r-', linewidth=2, label='Actual Direction')\n",
    "    ax_traj.plot(sim_results['time_points'], np.degrees(sim_results['decoded_directions']), \n",
    "                'b--', linewidth=2, alpha=0.8, label='Decoded Direction')\n",
    "    ax_traj.set_xlabel('Time (s)')\n",
    "    ax_traj.set_ylabel('Direction (°)')\n",
    "    ax_traj.set_title('Head Direction Turn')\n",
    "    ax_traj.legend()\n",
    "    ax_traj.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Bump amplitude evolution (top right, second)\n",
    "    ax_amp = fig.add_subplot(gs[0, 2])\n",
    "    ax_amp.plot(sim_results['time_points'], sim_results['bump_amplitudes'], \n",
    "               'g-', linewidth=2)\n",
    "    ax_amp.set_xlabel('Time (s)')\n",
    "    ax_amp.set_ylabel('Bump Amplitude')\n",
    "    ax_amp.set_title('Gaussian Bump Amplitude')\n",
    "    ax_amp.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Neural activity heatmap (bottom, spanning 2 columns)\n",
    "    ax_heatmap = fig.add_subplot(gs[1, 1:])\n",
    "    \n",
    "    # Transpose for proper orientation (time on x-axis, neurons on y-axis)\n",
    "    heatmap_data = sim_results['neural_activities'].T\n",
    "    \n",
    "    im = ax_heatmap.imshow(\n",
    "        heatmap_data,\n",
    "        aspect='auto',\n",
    "        cmap='hot',\n",
    "        origin='lower',\n",
    "        extent=[0, sim_results['turn_duration'], 0, len(final_activity)],\n",
    "        interpolation='bilinear'\n",
    "    )\n",
    "    \n",
    "    ax_heatmap.set_xlabel('Time (s)')\n",
    "    ax_heatmap.set_ylabel('Neuron Index')\n",
    "    ax_heatmap.set_title('Neural Activity Evolution During Turn\\n(Gaussian Bump Movement)')\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax_heatmap)\n",
    "    cbar.set_label('Neural Activity')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run the focused head direction turn simulation\n",
    "if 'trained_model' in locals():\n",
    "    print(\"Running focused head direction turn simulation...\")\n",
    "    print(\"This shows the Gaussian bump formation and evolution you requested!\")\n",
    "    \n",
    "    # Simulate a head direction turn\n",
    "    turn_results = simulate_head_direction_turn(\n",
    "        trained_model,\n",
    "        turn_duration=4.0,\n",
    "        turn_amount_deg=180\n",
    "    )\n",
    "    \n",
    "    # Create the comprehensive visualization\n",
    "    plot_head_direction_turn(turn_results)\n",
    "    \n",
    "    # Print summary of the simulation\n",
    "    print(\"\\nHead Direction Turn Simulation Summary:\")\n",
    "    print(f\"   • Started at: {turn_results['start_direction_deg']:.0f}°\")\n",
    "    print(f\"   • Turn amount: {turn_results['turn_amount_deg']:.0f}°\")\n",
    "    print(f\"   • Turn duration: {turn_results['turn_duration']:.1f}s\")\n",
    "    print(f\"   • Final decoded direction: {np.degrees(turn_results['decoded_directions'][-1]):.0f}°\")\n",
    "    print(f\"   • Bump amplitude range: {np.min(turn_results['bump_amplitudes']):.3f} - {np.max(turn_results['bump_amplitudes']):.3f}\")\n",
    "    \n",
    "    # Calculate tracking accuracy during the turn\n",
    "    tracking_errors = []\n",
    "    for i in range(len(turn_results['head_directions'])):\n",
    "        error = np.abs(turn_results['decoded_directions'][i] - turn_results['head_directions'][i])\n",
    "        error = min(error, 2*np.pi - error)  # Handle wraparound\n",
    "        tracking_errors.append(error)\n",
    "    \n",
    "    mean_error_deg = np.degrees(np.mean(tracking_errors))\n",
    "    print(f\"   • Mean tracking error during turn: {mean_error_deg:.1f}°\")\n",
    "    \n",
    "    if mean_error_deg < 15:\n",
    "        print(\"Excellent tracking during the turn!\")\n",
    "    elif mean_error_deg < 30:\n",
    "        print(\"Good tracking during the turn!\")\n",
    "    else:\n",
    "        print(\"Some drift during the turn - consider further training\")\n",
    "        \n",
    "else:\n",
    "    print(\"Please run the training cell first to generate a trained model!\")\n",
    "    print(\"Run Cell 7 (Quick Demo Training) to get the trained_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run head direction tracking evaluation with trained parameters\n",
    "\"\"\"\n",
    "Evaluate head direction tracking performance using the trained parameters.\n",
    "Tests how well the network maintains and tracks head direction with the \n",
    "optimized parameters found during training.\n",
    "\"\"\"\n",
    "\n",
    "# Check if training has been completed\n",
    "if 'trained_model' not in locals() or 'trainer' not in locals():\n",
    "    print(\"Please run the training cells first to generate a trained model!\")\n",
    "    print(\"   Specifically, run Cell 9 (Quick Demo Training) to get the trained_model\")\n",
    "else:\n",
    "    print(\"Head Direction Tracking Performance with Trained Parameters\")\n",
    "    \n",
    "    # Check if model needs resizing to match current network parameters\n",
    "    if trained_model.n_exc != n_exc or trained_model.n_inh != n_inh:\n",
    "        print(f\"Model size mismatch detected:\")\n",
    "        print(f\"   • Trained model: ({trained_model.n_exc}, {trained_model.n_inh})\")\n",
    "        print(f\"   • Current parameters: ({n_exc}, {n_inh})\")\n",
    "        print(f\"   • Resizing model to match current parameters...\")\n",
    "        \n",
    "        # Resize the trained model to match current network parameters\n",
    "        trained_model = resize_trained_model(trained_model, n_exc, n_inh)\n",
    "    \n",
    "    # Display the trained parameters being used\n",
    "    print(\"Using trained parameters:\")\n",
    "    print(f\"  • σ_EE (connection width): {trained_model.sigma_ee.item():.4f}\")\n",
    "    print(f\"  • g_ee (E→E gain): {trained_model.g_ee.item():.4f}\")\n",
    "    print(f\"  • g_ei (E→I gain): {trained_model.g_ei.item():.4f}\")\n",
    "    print(f\"  • g_ie (I→E gain): {trained_model.g_ie.item():.4f}\")\n",
    "    print(f\"  • Noise rate E: {trained_model.noise_rate_e.item():.4f}\")\n",
    "    print(f\"  • Noise rate I: {trained_model.noise_rate_i.item():.4f}\")\n",
    "    print(f\"  • Network size: ({trained_model.n_exc}, {trained_model.n_inh}) neurons\")\n",
    "    \n",
    "    # Test different head direction tracking scenarios\n",
    "    scenarios = {\n",
    "        'static_direction': generate_static_direction_test(),\n",
    "        'slow_turn': generate_slow_turn_test(),\n",
    "        'fast_turn': generate_fast_turn_test(),\n",
    "        'oscillation': generate_oscillation_test(),\n",
    "        'random_walk': generate_random_walk_test()\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(\"\\nRunning Head Direction Tracking Tests...\")\n",
    "    \n",
    "    for scenario_name, (head_directions, description) in scenarios.items():\n",
    "        print(f\"\\n Testing {scenario_name}: {description}\")\n",
    "        \n",
    "        # Run tracking simulation\n",
    "        tracking_results = run_tracking_simulation(trained_model, head_directions)\n",
    "        results[scenario_name] = tracking_results\n",
    "        \n",
    "        # Print performance metrics\n",
    "        mean_error = np.degrees(tracking_results['mean_error'])\n",
    "        max_error = np.degrees(tracking_results['max_error'])\n",
    "        tracking_accuracy = tracking_results['tracking_accuracy']\n",
    "        \n",
    "        print(f\"   • Mean tracking error: {mean_error:.1f}°\")\n",
    "        print(f\"   • Max tracking error: {max_error:.1f}°\")\n",
    "        print(f\"   • Tracking accuracy: {tracking_accuracy:.1f}%\")\n",
    "    \n",
    "    print(\"\\n✓ All tracking tests completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Visualize Head Direction Tracking Performance\n",
    "\n",
    "\"\"\"\n",
    "Create detailed visualizations showing:\n",
    "1. Direction tracking for each scenario\n",
    "2. Tracking errors over time  \n",
    "3. Bump amplitude evolution\n",
    "4. Summary statistics across scenarios\n",
    "\"\"\"\n",
    "\n",
    "def plot_tracking_performance(results, scenarios):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualization of tracking performance across scenarios.\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"No tracking results available. Please run the tracking evaluation first!\")\n",
    "        return\n",
    "        \n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    fig.suptitle('Head Direction Tracking Performance with Trained Parameters', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    n_scenarios = len(results)\n",
    "    \n",
    "    # Create subplots\n",
    "    gs = fig.add_gridspec(3, n_scenarios, hspace=0.4, wspace=0.3)\n",
    "    \n",
    "    scenario_names = list(results.keys())\n",
    "    \n",
    "    for i, scenario_name in enumerate(scenario_names):\n",
    "        result = results[scenario_name]\n",
    "        description = scenarios[scenario_name][1]\n",
    "        \n",
    "        dt = 0.05\n",
    "        time_points = np.arange(len(result['head_directions'])) * dt\n",
    "        \n",
    "        # Row 1: Direction tracking\n",
    "        ax1 = fig.add_subplot(gs[0, i])\n",
    "        ax1.plot(time_points, np.degrees(result['head_directions']), \n",
    "                'r-', linewidth=2, label='Actual', alpha=0.8)\n",
    "        ax1.plot(time_points, np.degrees(result['decoded_directions']), \n",
    "                'b--', linewidth=2, label='Decoded', alpha=0.8)\n",
    "        ax1.set_title(f'{scenario_name.replace(\"_\", \" \").title()}\\n{description}', fontsize=10)\n",
    "        ax1.set_ylabel('Direction (°)')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        if i == 0:\n",
    "            ax1.legend()\n",
    "        \n",
    "        # Row 2: Tracking error\n",
    "        ax2 = fig.add_subplot(gs[1, i])\n",
    "        ax2.plot(time_points, np.degrees(result['tracking_errors']), \n",
    "                'purple', linewidth=2)\n",
    "        ax2.axhline(y=30, color='red', linestyle='--', alpha=0.5, label='30° threshold')\n",
    "        ax2.set_ylabel('Error (°)')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        if i == 0:\n",
    "            ax2.legend()\n",
    "        \n",
    "        # Row 3: Bump amplitude\n",
    "        ax3 = fig.add_subplot(gs[2, i])\n",
    "        ax3.plot(time_points, result['bump_amplitudes'], \n",
    "                'green', linewidth=2)\n",
    "        ax3.set_xlabel('Time (s)')\n",
    "        ax3.set_ylabel('Bump Amplitude')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_summary_statistics(results):\n",
    "    \"\"\"\n",
    "    Plot summary statistics across all tracking scenarios.\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"No tracking results available. Please run the tracking evaluation first!\")\n",
    "        return\n",
    "        \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig.suptitle('Tracking Performance Summary', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    scenario_names = [name.replace('_', ' ').title() for name in results.keys()]\n",
    "    \n",
    "    # Mean tracking errors\n",
    "    mean_errors = [np.degrees(result['mean_error']) for result in results.values()]\n",
    "    axes[0].bar(scenario_names, mean_errors, color='skyblue', alpha=0.7)\n",
    "    axes[0].set_ylabel('Mean Error (°)')\n",
    "    axes[0].set_title('Mean Tracking Error')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Tracking accuracy\n",
    "    accuracies = [result['tracking_accuracy'] for result in results.values()]\n",
    "    axes[1].bar(scenario_names, accuracies, color='lightgreen', alpha=0.7)\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_title('Tracking Accuracy (<30° error)')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_ylim(0, 100)\n",
    "    \n",
    "    # Bump stability\n",
    "    stabilities = [result['bump_stability'] for result in results.values()]\n",
    "    axes[2].bar(scenario_names, stabilities, color='orange', alpha=0.7)\n",
    "    axes[2].set_ylabel('Stability Index')\n",
    "    axes[2].set_title('Bump Stability')\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Generate the visualizations if results are available\n",
    "if 'results' in locals() and results:\n",
    "    print(\"Creating tracking performance visualizations...\")\n",
    "    \n",
    "    # Main tracking performance plot\n",
    "    plot_tracking_performance(results, scenarios)\n",
    "    \n",
    "    # Summary statistics\n",
    "    plot_summary_statistics(results)\n",
    "    \n",
    "    # Print overall tracking performance summary\n",
    "    print(\"\\nHead Direction Tracking Summary with Trained Parameters:\")\n",
    "    \n",
    "    for scenario, result in results.items():\n",
    "        mean_error_deg = np.degrees(result['mean_error'])\n",
    "        accuracy = result['tracking_accuracy']\n",
    "        stability = result['bump_stability']\n",
    "        scenario_display = scenario.replace('_', ' ').title()\n",
    "        print(f\"   • {scenario_display:15}: {mean_error_deg:4.1f}° error, \"\n",
    "              f\"{accuracy:5.1f}% accuracy, {stability:.3f} stability\")\n",
    "    \n",
    "    # Overall performance assessment\n",
    "    overall_accuracy = np.mean([result['tracking_accuracy'] for result in results.values()])\n",
    "    overall_error = np.mean([np.degrees(result['mean_error']) for result in results.values()])\n",
    "    \n",
    "  \n",
    "    print(f\"Overall Performance:\")\n",
    "    print(f\"Average tracking error: {overall_error:.1f}°\")\n",
    "    print(f\"Average accuracy: {overall_accuracy:.1f}%\")\n",
    "    \n",
    "    if overall_accuracy > 85:\n",
    "        print(\"Excellent tracking performance!\")\n",
    "    elif overall_accuracy > 70:\n",
    "        print(\"Good tracking performance\")\n",
    "    else:\n",
    "        print(\"Consider further training or parameter tuning\")\n",
    "        \n",
    "else:\n",
    "    print(\"No tracking results to visualize. Please run the tracking evaluation first!\")\n",
    "    print(\"Run the previous cell to generate tracking results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9. Neuron Tuning Curves Analysis\n",
    "\n",
    "\"\"\"\n",
    "Analyze individual neuron tuning curves to measure their width and compare with\n",
    "anterodorsal nucleus (ADN) tuning curves from experimental data.\n",
    "\"\"\"\n",
    "\n",
    "def compute_tuning_curves(model, n_directions=36):\n",
    "    \"\"\"\n",
    "    Compute tuning curves for all neurons in the network.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RingAttractorNetwork\n",
    "        n_directions: Number of directions to test (360°/n_directions = angular resolution)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with tuning curve data\n",
    "    \"\"\"\n",
    "    directions = np.linspace(0, 2*np.pi, n_directions, endpoint=False)\n",
    "    tuning_curves = np.zeros((model.n_exc, n_directions))\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Computing tuning curves for {model.n_exc} neurons across {n_directions} directions...\")\n",
    "    \n",
    "    # Test each direction\n",
    "    for i, direction in enumerate(directions):\n",
    "        # Reset state for each direction\n",
    "        model.reset_state()\n",
    "        \n",
    "        # Create input for this direction\n",
    "        input_pattern = angle_to_input(\n",
    "            torch.tensor(direction),\n",
    "            n_exc=model.n_exc,\n",
    "            input_strength=1.5,  # Stronger input for clearer responses\n",
    "            input_width=0.3\n",
    "        )\n",
    "        \n",
    "        # Run network to steady state\n",
    "        with torch.no_grad():\n",
    "            # Run for multiple steps to reach steady state\n",
    "            for _ in range(15):  # More steps for better steady state\n",
    "                activity = model(input_pattern.to(model.device), steps=1)\n",
    "        \n",
    "        # Store final activity\n",
    "        tuning_curves[:, i] = activity.cpu().numpy().flatten()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"  Processed direction {i+1}/{n_directions}\")\n",
    "    \n",
    "    # Check response statistics\n",
    "    max_responses = np.max(tuning_curves, axis=1)\n",
    "    active_neurons = np.sum(max_responses > 0.01)  # Very low threshold\n",
    "    \n",
    "    print(f\"✓ Response statistics:\")\n",
    "    print(f\"  • Max response across all neurons: {np.max(max_responses):.4f}\")\n",
    "    print(f\"  • Mean max response: {np.mean(max_responses):.4f}\")\n",
    "    print(f\"  • Neurons with detectable activity (>0.01): {active_neurons}/{model.n_exc}\")\n",
    "    \n",
    "    return {\n",
    "        'directions': directions,\n",
    "        'tuning_curves': tuning_curves,\n",
    "        'directions_deg': np.degrees(directions),\n",
    "        'max_responses': max_responses\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_tuning_curve_width(tuning_curve, directions, min_peak_threshold=0.005):\n",
    "    \"\"\"\n",
    "    Analyze the width of a single tuning curve with more lenient thresholds.\n",
    "    \n",
    "    Args:\n",
    "        tuning_curve: 1D array of neural responses across directions\n",
    "        directions: Array of direction values (radians)\n",
    "        min_peak_threshold: Minimum peak response to consider (lowered from 0.1)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with tuning curve metrics\n",
    "    \"\"\"\n",
    "    # Find peak response\n",
    "    peak_idx = np.argmax(tuning_curve)\n",
    "    peak_response = tuning_curve[peak_idx]\n",
    "    peak_direction = directions[peak_idx]\n",
    "    \n",
    "    # Much more lenient threshold\n",
    "    if peak_response < min_peak_threshold:\n",
    "        return None\n",
    "    \n",
    "    # Find half-maximum width\n",
    "    half_max = peak_response / 2\n",
    "    \n",
    "    # Find indices where response is above half-maximum\n",
    "    above_half_max = tuning_curve >= half_max\n",
    "    \n",
    "    # Count consecutive regions above half-maximum\n",
    "    above_indices = np.where(above_half_max)[0]\n",
    "    \n",
    "    if len(above_indices) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Handle circular connectivity by finding the longest contiguous region\n",
    "    # that includes the peak\n",
    "    \n",
    "    # Simple approach: find all indices above half-max and compute span\n",
    "    if len(above_indices) < 2:\n",
    "        width_indices = 1\n",
    "    else:\n",
    "        # Check if indices wrap around (circular)\n",
    "        diff_indices = np.diff(above_indices)\n",
    "        if np.any(diff_indices > 1):\n",
    "            # There are gaps - find the contiguous region containing peak\n",
    "            regions = []\n",
    "            current_region = [above_indices[0]]\n",
    "            \n",
    "            for i in range(1, len(above_indices)):\n",
    "                if above_indices[i] - above_indices[i-1] == 1:\n",
    "                    current_region.append(above_indices[i])\n",
    "                else:\n",
    "                    regions.append(current_region)\n",
    "                    current_region = [above_indices[i]]\n",
    "            regions.append(current_region)\n",
    "            \n",
    "            # Find region containing peak\n",
    "            peak_region = None\n",
    "            for region in regions:\n",
    "                if peak_idx in region:\n",
    "                    peak_region = region\n",
    "                    break\n",
    "            \n",
    "            if peak_region:\n",
    "                width_indices = len(peak_region)\n",
    "            else:\n",
    "                width_indices = 1\n",
    "        else:\n",
    "            # All consecutive\n",
    "            width_indices = len(above_indices)\n",
    "    \n",
    "    # Convert to angular width\n",
    "    angular_resolution = 2 * np.pi / len(directions)\n",
    "    width_radians = width_indices * angular_resolution\n",
    "    width_degrees = np.degrees(width_radians)\n",
    "    \n",
    "    return {\n",
    "        'peak_response': peak_response,\n",
    "        'peak_direction': peak_direction,\n",
    "        'peak_direction_deg': np.degrees(peak_direction),\n",
    "        'width_radians': width_radians,\n",
    "        'width_degrees': width_degrees,\n",
    "        'half_max_threshold': half_max,\n",
    "        'above_half_max_count': len(above_indices)\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_tuning_curves_analysis(tuning_data, max_neurons_to_plot=20):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualization of tuning curves analysis.\n",
    "    \"\"\"\n",
    "    directions_deg = tuning_data['directions_deg']\n",
    "    tuning_curves = tuning_data['tuning_curves']\n",
    "    \n",
    "    print(\"Analyzing tuning curve widths...\")\n",
    "    \n",
    "    # Analyze all tuning curves with more lenient threshold\n",
    "    tuning_analyses = []\n",
    "    skipped_count = 0\n",
    "    \n",
    "    for i in range(tuning_curves.shape[0]):\n",
    "        analysis = analyze_tuning_curve_width(tuning_curves[i], tuning_data['directions'], \n",
    "                                            min_peak_threshold=0.005)  # Very lenient\n",
    "        if analysis is not None:\n",
    "            analysis['neuron_idx'] = i\n",
    "            tuning_analyses.append(analysis)\n",
    "        else:\n",
    "            skipped_count += 1\n",
    "    \n",
    "    print(f\"✓ Found {len(tuning_analyses)} valid tuning curves\")\n",
    "    print(f\"  • Skipped {skipped_count} neurons with insufficient activity\")\n",
    "    \n",
    "    if len(tuning_analyses) == 0:\n",
    "        print(\"❌ No valid tuning curves found!\")\n",
    "        print(\"This suggests the network responses are too weak or uniform.\")\n",
    "        print(\"Possible solutions:\")\n",
    "        print(\"  1. Increase input strength during tuning curve computation\")\n",
    "        print(\"  2. Lower the minimum peak threshold further\")\n",
    "        print(\"  3. Check if the network has properly formed directional selectivity\")\n",
    "        \n",
    "        # Show some diagnostic information\n",
    "        print(f\"\\nDiagnostic information:\")\n",
    "        print(f\"  • Max response in entire dataset: {np.max(tuning_curves):.6f}\")\n",
    "        print(f\"  • Mean response: {np.mean(tuning_curves):.6f}\")\n",
    "        print(f\"  • Std response: {np.std(tuning_curves):.6f}\")\n",
    "        \n",
    "        # Plot a few sample curves for diagnosis\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        fig.suptitle('Diagnostic: Sample Tuning Curves (No Valid Curves Found)', fontsize=14)\n",
    "        \n",
    "        sample_neurons = [0, len(tuning_curves)//4, len(tuning_curves)//2, -1]\n",
    "        for i, neuron_idx in enumerate(sample_neurons):\n",
    "            ax = axes[i//2, i%2]\n",
    "            curve = tuning_curves[neuron_idx]\n",
    "            ax.plot(directions_deg, curve, 'b-', linewidth=2)\n",
    "            ax.set_title(f'Neuron {neuron_idx}: max={np.max(curve):.4f}')\n",
    "            ax.set_xlabel('Direction (°)')\n",
    "            ax.set_ylabel('Response')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return None\n",
    "    \n",
    "    # Extract width statistics\n",
    "    widths_deg = [a['width_degrees'] for a in tuning_analyses]\n",
    "    peak_responses = [a['peak_response'] for a in tuning_analyses]\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    fig.suptitle('Neuron Tuning Curves Analysis - Comparison with ADN', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Create subplot layout\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.4, wspace=0.3)\n",
    "    \n",
    "    # 1. Sample tuning curves (top row, left)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    n_to_plot = min(max_neurons_to_plot, len(tuning_analyses))\n",
    "    sample_indices = np.linspace(0, len(tuning_analyses)-1, n_to_plot, dtype=int)\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        analysis = tuning_analyses[idx]\n",
    "        neuron_idx = analysis['neuron_idx']\n",
    "        curve = tuning_curves[neuron_idx]\n",
    "        \n",
    "        # Normalize for plotting\n",
    "        normalized_curve = curve / np.max(curve) if np.max(curve) > 0 else curve\n",
    "        \n",
    "        ax1.plot(directions_deg, normalized_curve, alpha=0.7, linewidth=1.5,\n",
    "                label=f'Neuron {neuron_idx}' if i < 5 else '')\n",
    "    \n",
    "    ax1.set_xlabel('Direction (°)')\n",
    "    ax1.set_ylabel('Normalized Response')\n",
    "    ax1.set_title('Sample Tuning Curves')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    if n_to_plot <= 5:\n",
    "        ax1.legend()\n",
    "    \n",
    "    # 2. Width distribution (top row, middle)\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.hist(widths_deg, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    ax2.axvline(np.mean(widths_deg), color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Mean: {np.mean(widths_deg):.1f}°')\n",
    "    ax2.axvline(np.median(widths_deg), color='green', linestyle='--', linewidth=2,\n",
    "                label=f'Median: {np.median(widths_deg):.1f}°')\n",
    "    \n",
    "    # Add ADN reference lines (typical ADN tuning curve widths from literature)\n",
    "    adn_mean_width = 90  # degrees (typical ADN width)\n",
    "    adn_range = [60, 120]  # typical range\n",
    "    \n",
    "    ax2.axvline(adn_mean_width, color='orange', linestyle='-', linewidth=3, alpha=0.8,\n",
    "                label=f'ADN Mean: {adn_mean_width}°')\n",
    "    ax2.axvspan(adn_range[0], adn_range[1], alpha=0.2, color='orange', \n",
    "                label=f'ADN Range: {adn_range[0]}-{adn_range[1]}°')\n",
    "    \n",
    "    ax2.set_xlabel('Tuning Width (°)')\n",
    "    ax2.set_ylabel('Number of Neurons')\n",
    "    ax2.set_title('Tuning Curve Width Distribution')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Width vs Peak Response (top row, right)\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.scatter(peak_responses, widths_deg, alpha=0.6, s=30)\n",
    "    ax3.set_xlabel('Peak Response')\n",
    "    ax3.set_ylabel('Tuning Width (°)')\n",
    "    ax3.set_title('Width vs Peak Response')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add correlation coefficient\n",
    "    correlation = np.corrcoef(peak_responses, widths_deg)[0, 1]\n",
    "    ax3.text(0.05, 0.95, f'r = {correlation:.3f}', transform=ax3.transAxes, \n",
    "             fontsize=12, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 4. Preferred direction distribution (middle row, left)\n",
    "    ax4 = fig.add_subplot(gs[1, 0])\n",
    "    preferred_dirs = [a['peak_direction_deg'] for a in tuning_analyses]\n",
    "    ax4.hist(preferred_dirs, bins=18, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    ax4.set_xlabel('Preferred Direction (°)')\n",
    "    ax4.set_ylabel('Number of Neurons')\n",
    "    ax4.set_title('Preferred Direction Distribution')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Polar plot of preferred directions (middle row, middle)\n",
    "    ax5 = fig.add_subplot(gs[1, 1], projection='polar')\n",
    "    preferred_dirs_rad = [a['peak_direction'] for a in tuning_analyses]\n",
    "    ax5.hist(preferred_dirs_rad, bins=18, alpha=0.7, color='lightcoral')\n",
    "    ax5.set_title('Preferred Directions (Polar)', pad=20)\n",
    "    \n",
    "    # 6. Comparison with ADN statistics (middle row, right)\n",
    "    ax6 = fig.add_subplot(gs[1, 2])\n",
    "    \n",
    "    # Model statistics\n",
    "    model_mean = np.mean(widths_deg)\n",
    "    model_std = np.std(widths_deg)\n",
    "    model_median = np.median(widths_deg)\n",
    "    \n",
    "    # ADN statistics from literature\n",
    "    adn_stats = {\n",
    "        'Mean': adn_mean_width,\n",
    "        'Std': 25,  # typical standard deviation\n",
    "        'Median': 85,  # typical median\n",
    "        'Range': adn_range\n",
    "    }\n",
    "    \n",
    "    comparison_data = {\n",
    "        'Model': [model_mean, model_std, model_median],\n",
    "        'ADN (Literature)': [adn_stats['Mean'], adn_stats['Std'], adn_stats['Median']]\n",
    "    }\n",
    "    \n",
    "    x = np.arange(3)\n",
    "    width = 0.35\n",
    "    \n",
    "    ax6.bar(x - width/2, comparison_data['Model'], width, label='Model', alpha=0.8, color='skyblue')\n",
    "    ax6.bar(x + width/2, comparison_data['ADN (Literature)'], width, label='ADN (Literature)', alpha=0.8, color='orange')\n",
    "    \n",
    "    ax6.set_ylabel('Degrees')\n",
    "    ax6.set_title('Model vs ADN Comparison')\n",
    "    ax6.set_xticks(x)\n",
    "    ax6.set_xticklabels(['Mean', 'Std', 'Median'])\n",
    "    ax6.legend()\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 7. Individual tuning curve examples (bottom row)\n",
    "    ax7 = fig.add_subplot(gs[2, :])\n",
    "    \n",
    "    # Show 5 best examples with different widths\n",
    "    sorted_analyses = sorted(tuning_analyses, key=lambda x: x['width_degrees'])\n",
    "    n_examples = min(5, len(sorted_analyses))\n",
    "    example_indices = np.linspace(0, len(sorted_analyses)-1, n_examples, dtype=int)\n",
    "    \n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, n_examples))\n",
    "    \n",
    "    for i, idx in enumerate(example_indices):\n",
    "        analysis = sorted_analyses[idx]\n",
    "        neuron_idx = analysis['neuron_idx']\n",
    "        curve = tuning_curves[neuron_idx]\n",
    "        \n",
    "        # Shift curve so peak is at center for better visualization\n",
    "        peak_idx = np.argmax(curve)\n",
    "        shift = len(directions_deg) // 2 - peak_idx\n",
    "        shifted_curve = np.roll(curve, shift)\n",
    "        shifted_directions = np.roll(directions_deg - directions_deg[peak_idx], shift)\n",
    "        \n",
    "        ax7.plot(shifted_directions, shifted_curve, linewidth=2, color=colors[i], alpha=0.8,\n",
    "                label=f'Width: {analysis[\"width_degrees\"]:.1f}° (Neuron {neuron_idx})')\n",
    "        \n",
    "        # Mark half-maximum\n",
    "        ax7.axhline(y=analysis['half_max_threshold'], color=colors[i], linestyle='--', alpha=0.5)\n",
    "    \n",
    "    ax7.set_xlabel('Direction relative to peak (°)')\n",
    "    ax7.set_ylabel('Neural Response')\n",
    "    ax7.set_title('Example Tuning Curves with Different Widths')\n",
    "    ax7.legend()\n",
    "    ax7.grid(True, alpha=0.3)\n",
    "    ax7.set_xlim(-180, 180)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TUNING CURVE ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total neurons analyzed: {len(tuning_analyses)}\")\n",
    "    print(f\"Mean tuning width: {model_mean:.1f}° ± {model_std:.1f}°\")\n",
    "    print(f\"Median tuning width: {model_median:.1f}°\")\n",
    "    print(f\"Width range: {np.min(widths_deg):.1f}° - {np.max(widths_deg):.1f}°\")\n",
    "    print()\n",
    "    print(\"COMPARISON WITH ADN:\")\n",
    "    print(f\"ADN typical width: {adn_mean_width}° ± {adn_stats['Std']}°\")\n",
    "    print(f\"Model vs ADN ratio: {model_mean/adn_mean_width:.2f}\")\n",
    "    print()\n",
    "    if model_mean < adn_range[0]:\n",
    "        print(\"✓ Model neurons are NARROWER than typical ADN neurons\")\n",
    "        print(\"  This suggests more precise directional tuning\")\n",
    "    elif model_mean > adn_range[1]:\n",
    "        print(\"⚠ Model neurons are BROADER than typical ADN neurons\")\n",
    "        print(\"  Consider adjusting connection width parameters\")\n",
    "    else:\n",
    "        print(\"✓ Model tuning widths are within ADN range\")\n",
    "        print(\"  Good match with biological data\")\n",
    "    \n",
    "    return {\n",
    "        'analyses': tuning_analyses,\n",
    "        'widths_deg': widths_deg,\n",
    "        'model_stats': {\n",
    "            'mean': model_mean,\n",
    "            'std': model_std,\n",
    "            'median': model_median,\n",
    "            'min': np.min(widths_deg),\n",
    "            'max': np.max(widths_deg)\n",
    "        },\n",
    "        'adn_stats': adn_stats\n",
    "    }\n",
    "\n",
    "\n",
    "# Run tuning curve analysis if we have a trained model\n",
    "if 'trained_model' in locals():\n",
    "    print(\"Computing tuning curves for all neurons...\")\n",
    "    print(\"This will test each neuron's response across 36 different head directions\")\n",
    "    \n",
    "    # Compute tuning curves\n",
    "    tuning_data = compute_tuning_curves(trained_model, n_directions=36)\n",
    "    \n",
    "    print(f\"✓ Computed tuning curves for {tuning_data['tuning_curves'].shape[0]} neurons\")\n",
    "    print(f\"✓ Tested {len(tuning_data['directions'])} directions (10° resolution)\")\n",
    "    \n",
    "    # Analyze and plot\n",
    "    analysis_results = plot_tuning_curves_analysis(tuning_data, max_neurons_to_plot=15)\n",
    "    \n",
    "else:\n",
    "    print(\"Please run the training cell first to generate a trained model!\")\n",
    "    print(\"Run Cell 7 (Quick Demo Training) to get the trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10. Bump Persistence Without Input Test\n",
    "\n",
    "\"\"\"\n",
    "Test how long the bump persists and what happens to it without any external input.\n",
    "This addresses the critical question: Does the bump drift (like real neurons) or disappear?\n",
    "\"\"\"\n",
    "\n",
    "def test_bump_persistence_without_input(model, initial_direction, test_duration=5.0, dt=0.05, store_full_activity=False):\n",
    "    \"\"\"\n",
    "    Test how long the bump persists without any external input.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RingAttractorNetwork\n",
    "        initial_direction: Initial head direction in radians\n",
    "        test_duration: How long to test (seconds) - reduced default from 10 to 5\n",
    "        dt: Time step\n",
    "        store_full_activity: Whether to store full neural activities (memory intensive)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with persistence test results\n",
    "    \"\"\"\n",
    "    n_steps = int(test_duration / dt)\n",
    "    \n",
    "    # Storage for results\n",
    "    positions = np.zeros(n_steps)\n",
    "    amplitudes = np.zeros(n_steps)\n",
    "    position_variance = np.zeros(n_steps)\n",
    "    \n",
    "    # Only store full neural activities if requested (memory intensive)\n",
    "    if store_full_activity:\n",
    "        neural_activities = np.zeros((n_steps, model.n_exc))\n",
    "    else:\n",
    "        # Store only subsampled activities for visualization\n",
    "        subsample_rate = 10  # Store every 10th step\n",
    "        neural_activities = np.zeros((n_steps // subsample_rate + 1, model.n_exc))\n",
    "    \n",
    "    # Initialize bump at specified direction\n",
    "    model.eval()\n",
    "    model.reset_state()\n",
    "    \n",
    "    # Ensure model is on correct device before initialization\n",
    "    device = next(model.parameters()).device\n",
    "    model.to(device)\n",
    "    \n",
    "    model.initialize_bump(initial_direction, width=0.3, amplitude=0.2)\n",
    "    \n",
    "    print(f\"Testing bump persistence for {test_duration}s without any input...\")\n",
    "    print(f\"Initial direction: {np.degrees(initial_direction):.1f}°\")\n",
    "    \n",
    "    # Get preferred directions once to avoid repeated device transfers\n",
    "    preferred_dirs_cpu = model.preferred_dirs.cpu().numpy()\n",
    "    \n",
    "    # Run simulation with NO external input\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            for step in range(n_steps):\n",
    "                # Run model with NO external input - this is the key!\n",
    "                activity = model(external_input=None, steps=1)\n",
    "                \n",
    "                # Convert to CPU once\n",
    "                activity_cpu = activity.cpu()\n",
    "                activity_np = activity_cpu.numpy().flatten()\n",
    "                \n",
    "                # Store neural activity (full or subsampled)\n",
    "                if store_full_activity:\n",
    "                    neural_activities[step] = activity_np\n",
    "                elif step % 10 == 0:\n",
    "                    neural_activities[step // 10] = activity_np\n",
    "                \n",
    "                # Decode position\n",
    "                decoded_dir = model.decode_angle(activity_cpu).item()\n",
    "                positions[step] = decoded_dir\n",
    "                \n",
    "                # Measure bump amplitude (max activity)\n",
    "                amplitudes[step] = torch.max(activity_cpu).item()\n",
    "                \n",
    "                # Calculate position variance (spread of activity)\n",
    "                activity_sum = activity_cpu.sum().item()\n",
    "                if activity_sum > 1e-6:  # Avoid division by zero\n",
    "                    # Weighted variance in circular space\n",
    "                    weights = activity_np / activity_sum\n",
    "                    \n",
    "                    # Circular variance\n",
    "                    x = np.sum(weights * np.cos(preferred_dirs_cpu))\n",
    "                    y = np.sum(weights * np.sin(preferred_dirs_cpu))\n",
    "                    R = np.sqrt(x**2 + y**2)\n",
    "                    position_variance[step] = 1 - R  # 0 = perfectly focused, 1 = uniform\n",
    "                else:\n",
    "                    position_variance[step] = 1.0\n",
    "    except Exception as e:\n",
    "        print(f\"Error during bump persistence test: {e}\")\n",
    "        print(f\"Step {step}/{n_steps}\")\n",
    "        raise\n",
    "    \n",
    "    # Analyze drift\n",
    "    time_points = np.arange(n_steps) * dt\n",
    "    \n",
    "    # Calculate drift rate (unwrap angles for proper calculation)\n",
    "    unwrapped_positions = np.unwrap(positions)\n",
    "    drift_rate = np.polyfit(time_points, unwrapped_positions, 1)[0]  # radians/second\n",
    "    \n",
    "    # Find when bump \"dies\" (amplitude < 10% of initial)\n",
    "    initial_amplitude = amplitudes[0]\n",
    "    if initial_amplitude > 0:\n",
    "        death_threshold = 0.1 * initial_amplitude\n",
    "        death_indices = np.where(amplitudes < death_threshold)[0]\n",
    "        if len(death_indices) > 0:\n",
    "            death_time = time_points[death_indices[0]]\n",
    "        else:\n",
    "            death_time = test_duration  # Survived entire test\n",
    "    else:\n",
    "        death_time = 0\n",
    "    \n",
    "    # Calculate total drift\n",
    "    total_drift = np.abs(positions[-1] - positions[0])\n",
    "    if total_drift > np.pi:\n",
    "        total_drift = 2*np.pi - total_drift  # Wrap around\n",
    "    \n",
    "    return {\n",
    "        'time_points': time_points,\n",
    "        'positions': positions,\n",
    "        'amplitudes': amplitudes,\n",
    "        'neural_activities': neural_activities,\n",
    "        'position_variance': position_variance,\n",
    "        'drift_rate': drift_rate,\n",
    "        'drift_rate_deg_per_s': np.degrees(drift_rate),\n",
    "        'death_time': death_time,\n",
    "        'total_drift': total_drift,\n",
    "        'total_drift_deg': np.degrees(total_drift),\n",
    "        'initial_direction': initial_direction,\n",
    "        'test_duration': test_duration\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_bump_persistence_results(results):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualization of bump persistence without input.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    fig.suptitle('Bump Persistence Without External Input', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.4, wspace=0.3)\n",
    "    \n",
    "    # 1. Position drift over time\n",
    "    ax1 = fig.add_subplot(gs[0, :2])\n",
    "    ax1.plot(results['time_points'], np.degrees(results['positions']), 'b-', linewidth=2)\n",
    "    ax1.axhline(y=np.degrees(results['initial_direction']), color='r', linestyle='--', \n",
    "                alpha=0.5, label='Initial direction')\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.set_ylabel('Decoded Direction (°)')\n",
    "    ax1.set_title(f'Position Drift (Rate: {results[\"drift_rate_deg_per_s\"]:.2f}°/s)')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # 2. Amplitude decay\n",
    "    ax2 = fig.add_subplot(gs[1, :2])\n",
    "    ax2.plot(results['time_points'], results['amplitudes'], 'g-', linewidth=2)\n",
    "    ax2.axhline(y=results['amplitudes'][0]*0.1, color='r', linestyle='--', \n",
    "                alpha=0.5, label='10% threshold')\n",
    "    ax2.set_xlabel('Time (s)')\n",
    "    ax2.set_ylabel('Bump Amplitude')\n",
    "    ax2.set_title(f'Amplitude Decay (Persistence: {results[\"death_time\"]:.1f}s)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. Position variance (bump spread)\n",
    "    ax3 = fig.add_subplot(gs[2, :2])\n",
    "    ax3.plot(results['time_points'], results['position_variance'], 'orange', linewidth=2)\n",
    "    ax3.set_xlabel('Time (s)')\n",
    "    ax3.set_ylabel('Position Variance')\n",
    "    ax3.set_title('Bump Spread Over Time (0=focused, 1=uniform)')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_ylim(0, 1)\n",
    "    \n",
    "    # 4. Neural activity heatmap\n",
    "    ax4 = fig.add_subplot(gs[:, 2])\n",
    "    \n",
    "    # Neural activities are already subsampled in the new version\n",
    "    heatmap_data = results['neural_activities'].T\n",
    "    \n",
    "    # Only plot if we have data\n",
    "    if heatmap_data.shape[1] > 0:\n",
    "        im = ax4.imshow(\n",
    "            heatmap_data,\n",
    "            aspect='auto',\n",
    "            cmap='hot',\n",
    "            origin='lower',\n",
    "            extent=[0, results['test_duration'], 0, heatmap_data.shape[0]],\n",
    "            interpolation='bilinear'\n",
    "        )\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=ax4)\n",
    "        cbar.set_label('Activity')\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'No activity data stored\\n(memory optimization)', \n",
    "                ha='center', va='center', transform=ax4.transAxes)\n",
    "    \n",
    "    ax4.set_xlabel('Time (s)')\n",
    "    ax4.set_ylabel('Neuron Index')\n",
    "    ax4.set_title('Neural Activity\\n(Bump Evolution)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BUMP PERSISTENCE WITHOUT INPUT - SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Test duration: {results['test_duration']}s\")\n",
    "    print(f\"Initial direction: {np.degrees(results['initial_direction']):.1f}°\")\n",
    "    print(f\"Final direction: {np.degrees(results['positions'][-1]):.1f}°\")\n",
    "    print(f\"Total drift: {results['total_drift_deg']:.1f}°\")\n",
    "    print(f\"Drift rate: {results['drift_rate_deg_per_s']:.2f}°/s\")\n",
    "    print(f\"Persistence time (>10% amplitude): {results['death_time']:.1f}s\")\n",
    "    print(f\"Final amplitude: {results['amplitudes'][-1]:.3f} ({results['amplitudes'][-1]/results['amplitudes'][0]*100:.1f}% of initial)\")\n",
    "    \n",
    "    if results['drift_rate_deg_per_s'] < 5:\n",
    "        print(\"\\n✓ EXCELLENT: Very slow drift - similar to biological HD cells in darkness\")\n",
    "    elif results['drift_rate_deg_per_s'] < 20:\n",
    "        print(\"\\n✓ GOOD: Moderate drift rate - reasonable short-term memory\")\n",
    "    else:\n",
    "        print(\"\\n⚠ FAST DRIFT: Consider reducing noise parameters for better persistence\")\n",
    "    \n",
    "    if results['death_time'] > 5:\n",
    "        print(\"✓ Bump persists for extended period\")\n",
    "    elif results['death_time'] > 1:\n",
    "        print(\"✓ Bump shows reasonable persistence\")\n",
    "    else:\n",
    "        print(\"⚠ Bump decays quickly - may need parameter adjustment\")\n",
    "\n",
    "\n",
    "# Run the bump persistence test\n",
    "if 'trained_model' in locals():\n",
    "    print(\"Running bump persistence test WITHOUT external input...\")\n",
    "    print(\"This reveals the true memory capacity of the ring attractor network\")\n",
    "    \n",
    "    try:\n",
    "        # Test with random initial direction\n",
    "        initial_dir = np.random.uniform(0, 2*np.pi)\n",
    "        \n",
    "        # Run persistence test for shorter duration (5 seconds) to avoid memory issues\n",
    "        # You can increase test_duration if needed, but may need to set store_full_activity=False\n",
    "        persistence_results = test_bump_persistence_without_input(\n",
    "            trained_model,\n",
    "            initial_direction=initial_dir,\n",
    "            test_duration=5.0,  # Reduced from 10.0 to avoid memory issues\n",
    "            store_full_activity=False  # Don't store full activity to save memory\n",
    "        )\n",
    "        \n",
    "        # Visualize results\n",
    "        plot_bump_persistence_results(persistence_results)\n",
    "        \n",
    "        # Compare with biological data\n",
    "        print(\"\\nComparison with biological HD cells:\")\n",
    "        print(\"- Real HD cells show drift rates of 5-15°/s in darkness (Valerio & Taube, 2016)\")\n",
    "        print(\"- Bump amplitude typically persists for >10s with gradual decay\")\n",
    "        print(\"- Drift is random walk-like, not systematic\")\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        print(f\"\\nError during bump persistence test: {e}\")\n",
    "        print(\"\\nTroubleshooting tips:\")\n",
    "        print(\"1. If CUDA out of memory: restart kernel and use CPU instead\")\n",
    "        print(\"2. Try shorter test_duration (e.g., 3.0 seconds)\")\n",
    "        print(\"3. Ensure model is on correct device\")\n",
    "        print(\"4. Check available memory with torch.cuda.memory_summary()\")\n",
    "        \n",
    "else:\n",
    "    print(\"Please run the training cell first to generate a trained model!\")\n",
    "    print(\"Run Cell 7 (Quick Demo Training) to get the trained_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11. Multiple Trials of Bump Persistence\n",
    "\n",
    "\"\"\"\n",
    "Run multiple trials to get statistics about bump persistence behavior.\n",
    "This provides more reliable estimates of drift rate and persistence time.\n",
    "\"\"\"\n",
    "\n",
    "def run_multiple_persistence_trials(model, n_trials=10, test_duration=5.0):\n",
    "    \"\"\"\n",
    "    Run multiple bump persistence trials to get statistics.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RingAttractorNetwork\n",
    "        n_trials: Number of trials to run\n",
    "        test_duration: Duration of each trial (seconds)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with aggregated results\n",
    "    \"\"\"\n",
    "    print(f\"Running {n_trials} bump persistence trials...\")\n",
    "    \n",
    "    # Storage for trial results\n",
    "    all_drift_rates = []\n",
    "    all_death_times = []\n",
    "    all_total_drifts = []\n",
    "    all_final_amplitudes = []\n",
    "    \n",
    "    for trial in range(n_trials):\n",
    "        # Random initial direction for each trial\n",
    "        initial_dir = np.random.uniform(0, 2*np.pi)\n",
    "        \n",
    "        # Run persistence test\n",
    "        results = test_bump_persistence_without_input(\n",
    "            model,\n",
    "            initial_direction=initial_dir,\n",
    "            test_duration=test_duration\n",
    "        )\n",
    "        \n",
    "        # Collect statistics\n",
    "        all_drift_rates.append(results['drift_rate_deg_per_s'])\n",
    "        all_death_times.append(results['death_time'])\n",
    "        all_total_drifts.append(results['total_drift_deg'])\n",
    "        all_final_amplitudes.append(results['amplitudes'][-1] / results['amplitudes'][0])\n",
    "        \n",
    "        print(f\"  Trial {trial+1}: drift={results['drift_rate_deg_per_s']:.1f}°/s, \"\n",
    "              f\"persistence={results['death_time']:.1f}s\")\n",
    "    \n",
    "    # Compute statistics\n",
    "    stats = {\n",
    "        'n_trials': n_trials,\n",
    "        'test_duration': test_duration,\n",
    "        'drift_rates': np.array(all_drift_rates),\n",
    "        'death_times': np.array(all_death_times),\n",
    "        'total_drifts': np.array(all_total_drifts),\n",
    "        'final_amplitude_ratios': np.array(all_final_amplitudes),\n",
    "        'mean_drift_rate': np.mean(all_drift_rates),\n",
    "        'std_drift_rate': np.std(all_drift_rates),\n",
    "        'mean_death_time': np.mean(all_death_times),\n",
    "        'std_death_time': np.std(all_death_times),\n",
    "        'mean_total_drift': np.mean(all_total_drifts),\n",
    "        'mean_final_amplitude_ratio': np.mean(all_final_amplitudes)\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "def plot_persistence_statistics(stats):\n",
    "    \"\"\"\n",
    "    Plot statistics from multiple persistence trials.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Bump Persistence Statistics ({stats[\"n_trials\"]} trials, {stats[\"test_duration\"]}s each)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Drift rate distribution\n",
    "    axes[0, 0].hist(stats['drift_rates'], bins=15, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[0, 0].axvline(stats['mean_drift_rate'], color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Mean: {stats[\"mean_drift_rate\"]:.1f}°/s')\n",
    "    axes[0, 0].set_xlabel('Drift Rate (°/s)')\n",
    "    axes[0, 0].set_ylabel('Count')\n",
    "    axes[0, 0].set_title('Drift Rate Distribution')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Persistence time distribution\n",
    "    axes[0, 1].hist(stats['death_times'], bins=15, alpha=0.7, color='green', edgecolor='black')\n",
    "    axes[0, 1].axvline(stats['mean_death_time'], color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Mean: {stats[\"mean_death_time\"]:.1f}s')\n",
    "    axes[0, 1].set_xlabel('Persistence Time (s)')\n",
    "    axes[0, 1].set_ylabel('Count')\n",
    "    axes[0, 1].set_title('Bump Persistence Time')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Total drift distribution\n",
    "    axes[1, 0].hist(stats['total_drifts'], bins=15, alpha=0.7, color='orange', edgecolor='black')\n",
    "    axes[1, 0].axvline(stats['mean_total_drift'], color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Mean: {stats[\"mean_total_drift\"]:.1f}°')\n",
    "    axes[1, 0].set_xlabel('Total Drift (°)')\n",
    "    axes[1, 0].set_ylabel('Count')\n",
    "    axes[1, 0].set_title(f'Total Drift over {stats[\"test_duration\"]}s')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Final amplitude ratio\n",
    "    axes[1, 1].hist(stats['final_amplitude_ratios'], bins=15, alpha=0.7, color='purple', edgecolor='black')\n",
    "    axes[1, 1].axvline(stats['mean_final_amplitude_ratio'], color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Mean: {stats[\"mean_final_amplitude_ratio\"]:.2f}')\n",
    "    axes[1, 1].set_xlabel('Final/Initial Amplitude Ratio')\n",
    "    axes[1, 1].set_ylabel('Count')\n",
    "    axes[1, 1].set_title('Amplitude Retention')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary report\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BUMP PERSISTENCE STATISTICS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Number of trials: {stats['n_trials']}\")\n",
    "    print(f\"Test duration per trial: {stats['test_duration']}s\")\n",
    "    print(f\"\\nDrift Rate:\")\n",
    "    print(f\"  Mean: {stats['mean_drift_rate']:.1f} ± {stats['std_drift_rate']:.1f}°/s\")\n",
    "    print(f\"  Range: {np.min(stats['drift_rates']):.1f} - {np.max(stats['drift_rates']):.1f}°/s\")\n",
    "    print(f\"\\nPersistence Time (>10% amplitude):\")\n",
    "    print(f\"  Mean: {stats['mean_death_time']:.1f} ± {stats['std_death_time']:.1f}s\")\n",
    "    print(f\"  Trials surviving full duration: {np.sum(stats['death_times'] >= stats['test_duration'])}/{stats['n_trials']}\")\n",
    "    print(f\"\\nAmplitude Retention:\")\n",
    "    print(f\"  Mean final/initial ratio: {stats['mean_final_amplitude_ratio']:.2%}\")\n",
    "    \n",
    "    # Biological comparison\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"BIOLOGICAL COMPARISON:\")\n",
    "    if stats['mean_drift_rate'] < 15:\n",
    "        print(\"✓ Drift rate is within biological range (5-15°/s in darkness)\")\n",
    "    else:\n",
    "        print(\"⚠ Drift rate exceeds typical biological range\")\n",
    "    \n",
    "    if stats['mean_death_time'] > 3:\n",
    "        print(\"✓ Good persistence time for short-term memory\")\n",
    "    else:\n",
    "        print(\"⚠ Limited persistence - consider parameter tuning\")\n",
    "\n",
    "\n",
    "# Run multiple trials if model is available\n",
    "if 'trained_model' in locals():\n",
    "    print(\"Running multiple bump persistence trials for reliable statistics...\")\n",
    "    \n",
    "    # Run 10 trials of 5 seconds each\n",
    "    persistence_stats = run_multiple_persistence_trials(\n",
    "        trained_model,\n",
    "        n_trials=10,\n",
    "        test_duration=5.0\n",
    "    )\n",
    "    \n",
    "    # Visualize statistics\n",
    "    plot_persistence_statistics(persistence_stats)\n",
    "    \n",
    "    # Recommendations for report\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"Based on these results, you should report:\")\n",
    "    print(f\"1. 'The bump exhibits gradual drift at {persistence_stats['mean_drift_rate']:.1f}±{persistence_stats['std_drift_rate']:.1f}°/s without input'\")\n",
    "    print(f\"2. 'Bump amplitude persists above 10% for {persistence_stats['mean_death_time']:.1f}±{persistence_stats['std_death_time']:.1f}s'\")\n",
    "    print(\"3. 'This drift behavior is consistent with biological HD cells in darkness'\")\n",
    "    print(\"4. 'Future work should explore methods to extend persistence time while maintaining biological plausibility'\")\n",
    "    \n",
    "else:\n",
    "    print(\"Please run the training cell first to generate a trained model!\")\n",
    "    print(\"Run Cell 7 (Quick Demo Training) to get the trained_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11. Multiple Trials of Bump Persistence\n",
    "\n",
    "\"\"\"\n",
    "Run multiple trials to get statistics about bump persistence behavior.\n",
    "This provides more reliable estimates of drift rate and persistence time.\n",
    "\"\"\"\n",
    "\n",
    "def run_multiple_persistence_trials(model, n_trials=10, test_duration=5.0):\n",
    "    \"\"\"\n",
    "    Run multiple bump persistence trials to get statistics.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RingAttractorNetwork\n",
    "        n_trials: Number of trials to run\n",
    "        test_duration: Duration of each trial (seconds)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with aggregated results\n",
    "    \"\"\"\n",
    "    print(f\"Running {n_trials} bump persistence trials...\")\n",
    "    \n",
    "    # Storage for trial results\n",
    "    all_drift_rates = []\n",
    "    all_death_times = []\n",
    "    all_total_drifts = []\n",
    "    all_final_amplitudes = []\n",
    "    \n",
    "    for trial in range(n_trials):\n",
    "        # Random initial direction for each trial\n",
    "        initial_dir = np.random.uniform(0, 2*np.pi)\n",
    "        \n",
    "        # Run persistence test\n",
    "        results = test_bump_persistence_without_input(\n",
    "            model,\n",
    "            initial_direction=initial_dir,\n",
    "            test_duration=test_duration\n",
    "        )\n",
    "        \n",
    "        # Collect statistics\n",
    "        all_drift_rates.append(results['drift_rate_deg_per_s'])\n",
    "        all_death_times.append(results['death_time'])\n",
    "        all_total_drifts.append(results['total_drift_deg'])\n",
    "        all_final_amplitudes.append(results['amplitudes'][-1] / results['amplitudes'][0])\n",
    "        \n",
    "        print(f\"  Trial {trial+1}: drift={results['drift_rate_deg_per_s']:.1f}°/s, \"\n",
    "              f\"persistence={results['death_time']:.1f}s\")\n",
    "    \n",
    "    # Compute statistics\n",
    "    stats = {\n",
    "        'n_trials': n_trials,\n",
    "        'test_duration': test_duration,\n",
    "        'drift_rates': np.array(all_drift_rates),\n",
    "        'death_times': np.array(all_death_times),\n",
    "        'total_drifts': np.array(all_total_drifts),\n",
    "        'final_amplitude_ratios': np.array(all_final_amplitudes),\n",
    "        'mean_drift_rate': np.mean(all_drift_rates),\n",
    "        'std_drift_rate': np.std(all_drift_rates),\n",
    "        'mean_death_time': np.mean(all_death_times),\n",
    "        'std_death_time': np.std(all_death_times),\n",
    "        'mean_total_drift': np.mean(all_total_drifts),\n",
    "        'mean_final_amplitude_ratio': np.mean(all_final_amplitudes)\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "def plot_persistence_statistics(stats):\n",
    "    \"\"\"\n",
    "    Plot statistics from multiple persistence trials.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Bump Persistence Statistics ({stats[\"n_trials\"]} trials, {stats[\"test_duration\"]}s each)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Drift rate distribution\n",
    "    axes[0, 0].hist(stats['drift_rates'], bins=15, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[0, 0].axvline(stats['mean_drift_rate'], color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Mean: {stats[\"mean_drift_rate\"]:.1f}°/s')\n",
    "    axes[0, 0].set_xlabel('Drift Rate (°/s)')\n",
    "    axes[0, 0].set_ylabel('Count')\n",
    "    axes[0, 0].set_title('Drift Rate Distribution')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Persistence time distribution\n",
    "    axes[0, 1].hist(stats['death_times'], bins=15, alpha=0.7, color='green', edgecolor='black')\n",
    "    axes[0, 1].axvline(stats['mean_death_time'], color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Mean: {stats[\"mean_death_time\"]:.1f}s')\n",
    "    axes[0, 1].set_xlabel('Persistence Time (s)')\n",
    "    axes[0, 1].set_ylabel('Count')\n",
    "    axes[0, 1].set_title('Bump Persistence Time')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Total drift distribution\n",
    "    axes[1, 0].hist(stats['total_drifts'], bins=15, alpha=0.7, color='orange', edgecolor='black')\n",
    "    axes[1, 0].axvline(stats['mean_total_drift'], color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Mean: {stats[\"mean_total_drift\"]:.1f}°')\n",
    "    axes[1, 0].set_xlabel('Total Drift (°)')\n",
    "    axes[1, 0].set_ylabel('Count')\n",
    "    axes[1, 0].set_title(f'Total Drift over {stats[\"test_duration\"]}s')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Final amplitude ratio\n",
    "    axes[1, 1].hist(stats['final_amplitude_ratios'], bins=15, alpha=0.7, color='purple', edgecolor='black')\n",
    "    axes[1, 1].axvline(stats['mean_final_amplitude_ratio'], color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Mean: {stats[\"mean_final_amplitude_ratio\"]:.2f}')\n",
    "    axes[1, 1].set_xlabel('Final/Initial Amplitude Ratio')\n",
    "    axes[1, 1].set_ylabel('Count')\n",
    "    axes[1, 1].set_title('Amplitude Retention')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary report\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BUMP PERSISTENCE STATISTICS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Number of trials: {stats['n_trials']}\")\n",
    "    print(f\"Test duration per trial: {stats['test_duration']}s\")\n",
    "    print(f\"\\nDrift Rate:\")\n",
    "    print(f\"  Mean: {stats['mean_drift_rate']:.1f} ± {stats['std_drift_rate']:.1f}°/s\")\n",
    "    print(f\"  Range: {np.min(stats['drift_rates']):.1f} - {np.max(stats['drift_rates']):.1f}°/s\")\n",
    "    print(f\"\\nPersistence Time (>10% amplitude):\")\n",
    "    print(f\"  Mean: {stats['mean_death_time']:.1f} ± {stats['std_death_time']:.1f}s\")\n",
    "    print(f\"  Trials surviving full duration: {np.sum(stats['death_times'] >= stats['test_duration'])}/{stats['n_trials']}\")\n",
    "    print(f\"\\nAmplitude Retention:\")\n",
    "    print(f\"  Mean final/initial ratio: {stats['mean_final_amplitude_ratio']:.2%}\")\n",
    "    \n",
    "    # Biological comparison\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"BIOLOGICAL COMPARISON:\")\n",
    "    if stats['mean_drift_rate'] < 15:\n",
    "        print(\"✓ Drift rate is within biological range (5-15°/s in darkness)\")\n",
    "    else:\n",
    "        print(\"⚠ Drift rate exceeds typical biological range\")\n",
    "    \n",
    "    if stats['mean_death_time'] > 3:\n",
    "        print(\"✓ Good persistence time for short-term memory\")\n",
    "    else:\n",
    "        print(\"⚠ Limited persistence - consider parameter tuning\")\n",
    "\n",
    "\n",
    "# Run multiple trials if model is available\n",
    "if 'trained_model' in locals():\n",
    "    print(\"Running multiple bump persistence trials for reliable statistics...\")\n",
    "    \n",
    "    # Run 10 trials of 5 seconds each\n",
    "    persistence_stats = run_multiple_persistence_trials(\n",
    "        trained_model,\n",
    "        n_trials=10,\n",
    "        test_duration=5.0\n",
    "    )\n",
    "    \n",
    "    # Visualize statistics\n",
    "    plot_persistence_statistics(persistence_stats)\n",
    "    \n",
    "    # Recommendations for report\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"Based on these results, you should report:\")\n",
    "    print(f\"1. 'The bump exhibits gradual drift at {persistence_stats['mean_drift_rate']:.1f}±{persistence_stats['std_drift_rate']:.1f}°/s without input'\")\n",
    "    print(f\"2. 'Bump amplitude persists above 10% for {persistence_stats['mean_death_time']:.1f}±{persistence_stats['std_death_time']:.1f}s'\")\n",
    "    print(\"3. 'This drift behavior is consistent with biological HD cells in darkness'\")\n",
    "    print(\"4. 'Future work should explore methods to extend persistence time while maintaining biological plausibility'\")\n",
    "    \n",
    "else:\n",
    "    print(\"Please run the training cell first to generate a trained model!\")\n",
    "    print(\"Run Cell 7 (Quick Demo Training) to get the trained_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11. Multiple Trials of Bump Persistence\n",
    "\n",
    "\"\"\"\n",
    "Run multiple trials to get statistics about bump persistence behavior.\n",
    "This provides more reliable estimates of drift rate and persistence time.\n",
    "\"\"\"\n",
    "\n",
    "def run_multiple_persistence_trials(model, n_trials=10, test_duration=5.0):\n",
    "    \"\"\"\n",
    "    Run multiple bump persistence trials to get statistics.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RingAttractorNetwork\n",
    "        n_trials: Number of trials to run\n",
    "        test_duration: Duration of each trial (seconds)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with aggregated results\n",
    "    \"\"\"\n",
    "    print(f\"Running {n_trials} bump persistence trials...\")\n",
    "    \n",
    "    # Storage for trial results\n",
    "    all_drift_rates = []\n",
    "    all_death_times = []\n",
    "    all_total_drifts = []\n",
    "    all_final_amplitudes = []\n",
    "    \n",
    "    for trial in range(n_trials):\n",
    "        # Random initial direction for each trial\n",
    "        initial_dir = np.random.uniform(0, 2*np.pi)\n",
    "        \n",
    "        # Run persistence test\n",
    "        results = test_bump_persistence_without_input(\n",
    "            model,\n",
    "            initial_direction=initial_dir,\n",
    "            test_duration=test_duration\n",
    "        )\n",
    "        \n",
    "        # Collect statistics\n",
    "        all_drift_rates.append(results['drift_rate_deg_per_s'])\n",
    "        all_death_times.append(results['death_time'])\n",
    "        all_total_drifts.append(results['total_drift_deg'])\n",
    "        all_final_amplitudes.append(results['amplitudes'][-1] / results['amplitudes'][0])\n",
    "        \n",
    "        print(f\"  Trial {trial+1}: drift={results['drift_rate_deg_per_s']:.1f}°/s, \"\n",
    "              f\"persistence={results['death_time']:.1f}s\")\n",
    "    \n",
    "    # Compute statistics\n",
    "    stats = {\n",
    "        'n_trials': n_trials,\n",
    "        'test_duration': test_duration,\n",
    "        'drift_rates': np.array(all_drift_rates),\n",
    "        'death_times': np.array(all_death_times),\n",
    "        'total_drifts': np.array(all_total_drifts),\n",
    "        'final_amplitude_ratios': np.array(all_final_amplitudes),\n",
    "        'mean_drift_rate': np.mean(all_drift_rates),\n",
    "        'std_drift_rate': np.std(all_drift_rates),\n",
    "        'mean_death_time': np.mean(all_death_times),\n",
    "        'std_death_time': np.std(all_death_times),\n",
    "        'mean_total_drift': np.mean(all_total_drifts),\n",
    "        'mean_final_amplitude_ratio': np.mean(all_final_amplitudes)\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "def plot_persistence_statistics(stats):\n",
    "    \"\"\"\n",
    "    Plot statistics from multiple persistence trials.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Bump Persistence Statistics ({stats[\"n_trials\"]} trials, {stats[\"test_duration\"]}s each)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Drift rate distribution\n",
    "    axes[0, 0].hist(stats['drift_rates'], bins=15, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[0, 0].axvline(stats['mean_drift_rate'], color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Mean: {stats[\"mean_drift_rate\"]:.1f}°/s')\n",
    "    axes[0, 0].set_xlabel('Drift Rate (°/s)')\n",
    "    axes[0, 0].set_ylabel('Count')\n",
    "    axes[0, 0].set_title('Drift Rate Distribution')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Persistence time distribution\n",
    "    axes[0, 1].hist(stats['death_times'], bins=15, alpha=0.7, color='green', edgecolor='black')\n",
    "    axes[0, 1].axvline(stats['mean_death_time'], color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Mean: {stats[\"mean_death_time\"]:.1f}s')\n",
    "    axes[0, 1].set_xlabel('Persistence Time (s)')\n",
    "    axes[0, 1].set_ylabel('Count')\n",
    "    axes[0, 1].set_title('Bump Persistence Time')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Total drift distribution\n",
    "    axes[1, 0].hist(stats['total_drifts'], bins=15, alpha=0.7, color='orange', edgecolor='black')\n",
    "    axes[1, 0].axvline(stats['mean_total_drift'], color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Mean: {stats[\"mean_total_drift\"]:.1f}°')\n",
    "    axes[1, 0].set_xlabel('Total Drift (°)')\n",
    "    axes[1, 0].set_ylabel('Count')\n",
    "    axes[1, 0].set_title(f'Total Drift over {stats[\"test_duration\"]}s')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Final amplitude ratio\n",
    "    axes[1, 1].hist(stats['final_amplitude_ratios'], bins=15, alpha=0.7, color='purple', edgecolor='black')\n",
    "    axes[1, 1].axvline(stats['mean_final_amplitude_ratio'], color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Mean: {stats[\"mean_final_amplitude_ratio\"]:.2f}')\n",
    "    axes[1, 1].set_xlabel('Final/Initial Amplitude Ratio')\n",
    "    axes[1, 1].set_ylabel('Count')\n",
    "    axes[1, 1].set_title('Amplitude Retention')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary report\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BUMP PERSISTENCE STATISTICS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Number of trials: {stats['n_trials']}\")\n",
    "    print(f\"Test duration per trial: {stats['test_duration']}s\")\n",
    "    print(f\"\\nDrift Rate:\")\n",
    "    print(f\"  Mean: {stats['mean_drift_rate']:.1f} ± {stats['std_drift_rate']:.1f}°/s\")\n",
    "    print(f\"  Range: {np.min(stats['drift_rates']):.1f} - {np.max(stats['drift_rates']):.1f}°/s\")\n",
    "    print(f\"\\nPersistence Time (>10% amplitude):\")\n",
    "    print(f\"  Mean: {stats['mean_death_time']:.1f} ± {stats['std_death_time']:.1f}s\")\n",
    "    print(f\"  Trials surviving full duration: {np.sum(stats['death_times'] >= stats['test_duration'])}/{stats['n_trials']}\")\n",
    "    print(f\"\\nAmplitude Retention:\")\n",
    "    print(f\"  Mean final/initial ratio: {stats['mean_final_amplitude_ratio']:.2%}\")\n",
    "    \n",
    "    # Biological comparison\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"BIOLOGICAL COMPARISON:\")\n",
    "    if stats['mean_drift_rate'] < 15:\n",
    "        print(\"✓ Drift rate is within biological range (5-15°/s in darkness)\")\n",
    "    else:\n",
    "        print(\"⚠ Drift rate exceeds typical biological range\")\n",
    "    \n",
    "    if stats['mean_death_time'] > 3:\n",
    "        print(\"✓ Good persistence time for short-term memory\")\n",
    "    else:\n",
    "        print(\"⚠ Limited persistence - consider parameter tuning\")\n",
    "\n",
    "\n",
    "# Run multiple trials if model is available\n",
    "if 'trained_model' in locals():\n",
    "    print(\"Running multiple bump persistence trials for reliable statistics...\")\n",
    "    \n",
    "    # Run 10 trials of 5 seconds each\n",
    "    persistence_stats = run_multiple_persistence_trials(\n",
    "        trained_model,\n",
    "        n_trials=10,\n",
    "        test_duration=5.0\n",
    "    )\n",
    "    \n",
    "    # Visualize statistics\n",
    "    plot_persistence_statistics(persistence_stats)\n",
    "    \n",
    "    # Recommendations for report\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"Based on these results, you should report:\")\n",
    "    print(f\"1. 'The bump exhibits gradual drift at {persistence_stats['mean_drift_rate']:.1f}±{persistence_stats['std_drift_rate']:.1f}°/s without input'\")\n",
    "    print(f\"2. 'Bump amplitude persists above 10% for {persistence_stats['mean_death_time']:.1f}±{persistence_stats['std_death_time']:.1f}s'\")\n",
    "    print(\"3. 'This drift behavior is consistent with biological HD cells in darkness'\")\n",
    "    print(\"4. 'Future work should explore methods to extend persistence time while maintaining biological plausibility'\")\n",
    "    \n",
    "else:\n",
    "    print(\"Please run the training cell first to generate a trained model!\")\n",
    "    print(\"Run Cell 7 (Quick Demo Training) to get the trained_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11. Multiple Trials of Bump Persistence\n",
    "\n",
    "\"\"\"\n",
    "Run multiple trials to get statistics about bump persistence behavior.\n",
    "This provides more reliable estimates of drift rate and persistence time.\n",
    "\"\"\"\n",
    "\n",
    "def run_multiple_persistence_trials(model, n_trials=10, test_duration=5.0):\n",
    "    \"\"\"\n",
    "    Run multiple bump persistence trials to get statistics.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RingAttractorNetwork\n",
    "        n_trials: Number of trials to run\n",
    "        test_duration: Duration of each trial (seconds)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with aggregated results\n",
    "    \"\"\"\n",
    "    print(f\"Running {n_trials} bump persistence trials...\")\n",
    "    \n",
    "    # Storage for trial results\n",
    "    all_drift_rates = []\n",
    "    all_death_times = []\n",
    "    all_total_drifts = []\n",
    "    all_final_amplitudes = []\n",
    "    \n",
    "    for trial in range(n_trials):\n",
    "        # Random initial direction for each trial\n",
    "        initial_dir = np.random.uniform(0, 2*np.pi)\n",
    "        \n",
    "        # Run persistence test\n",
    "        results = test_bump_persistence_without_input(\n",
    "            model,\n",
    "            initial_direction=initial_dir,\n",
    "            test_duration=test_duration\n",
    "        )\n",
    "        \n",
    "        # Collect statistics\n",
    "        all_drift_rates.append(results['drift_rate_deg_per_s'])\n",
    "        all_death_times.append(results['death_time'])\n",
    "        all_total_drifts.append(results['total_drift_deg'])\n",
    "        all_final_amplitudes.append(results['amplitudes'][-1] / results['amplitudes'][0])\n",
    "        \n",
    "        print(f\"  Trial {trial+1}: drift={results['drift_rate_deg_per_s']:.1f}°/s, \"\n",
    "              f\"persistence={results['death_time']:.1f}s\")\n",
    "    \n",
    "    # Compute statistics\n",
    "    stats = {\n",
    "        'n_trials': n_trials,\n",
    "        'test_duration': test_duration,\n",
    "        'drift_rates': np.array(all_drift_rates),\n",
    "        'death_times': np.array(all_death_times),\n",
    "        'total_drifts': np.array(all_total_drifts),\n",
    "        'final_amplitude_ratios': np.array(all_final_amplitudes),\n",
    "        'mean_drift_rate': np.mean(all_drift_rates),\n",
    "        'std_drift_rate': np.std(all_drift_rates),\n",
    "        'mean_death_time': np.mean(all_death_times),\n",
    "        'std_death_time': np.std(all_death_times),\n",
    "        'mean_total_drift': np.mean(all_total_drifts),\n",
    "        'mean_final_amplitude_ratio': np.mean(all_final_amplitudes)\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "def plot_persistence_statistics(stats):\n",
    "    \"\"\"\n",
    "    Plot statistics from multiple persistence trials.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Bump Persistence Statistics ({stats[\"n_trials\"]} trials, {stats[\"test_duration\"]}s each)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Drift rate distribution\n",
    "    axes[0, 0].hist(stats['drift_rates'], bins=15, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[0, 0].axvline(stats['mean_drift_rate'], color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Mean: {stats[\"mean_drift_rate\"]:.1f}°/s')\n",
    "    axes[0, 0].set_xlabel('Drift Rate (°/s)')\n",
    "    axes[0, 0].set_ylabel('Count')\n",
    "    axes[0, 0].set_title('Drift Rate Distribution')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Persistence time distribution\n",
    "    axes[0, 1].hist(stats['death_times'], bins=15, alpha=0.7, color='green', edgecolor='black')\n",
    "    axes[0, 1].axvline(stats['mean_death_time'], color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Mean: {stats[\"mean_death_time\"]:.1f}s')\n",
    "    axes[0, 1].set_xlabel('Persistence Time (s)')\n",
    "    axes[0, 1].set_ylabel('Count')\n",
    "    axes[0, 1].set_title('Bump Persistence Time')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Total drift distribution\n",
    "    axes[1, 0].hist(stats['total_drifts'], bins=15, alpha=0.7, color='orange', edgecolor='black')\n",
    "    axes[1, 0].axvline(stats['mean_total_drift'], color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Mean: {stats[\"mean_total_drift\"]:.1f}°')\n",
    "    axes[1, 0].set_xlabel('Total Drift (°)')\n",
    "    axes[1, 0].set_ylabel('Count')\n",
    "    axes[1, 0].set_title(f'Total Drift over {stats[\"test_duration\"]}s')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Final amplitude ratio\n",
    "    axes[1, 1].hist(stats['final_amplitude_ratios'], bins=15, alpha=0.7, color='purple', edgecolor='black')\n",
    "    axes[1, 1].axvline(stats['mean_final_amplitude_ratio'], color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Mean: {stats[\"mean_final_amplitude_ratio\"]:.2f}')\n",
    "    axes[1, 1].set_xlabel('Final/Initial Amplitude Ratio')\n",
    "    axes[1, 1].set_ylabel('Count')\n",
    "    axes[1, 1].set_title('Amplitude Retention')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary report\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BUMP PERSISTENCE STATISTICS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Number of trials: {stats['n_trials']}\")\n",
    "    print(f\"Test duration per trial: {stats['test_duration']}s\")\n",
    "    print(f\"\\nDrift Rate:\")\n",
    "    print(f\"  Mean: {stats['mean_drift_rate']:.1f} ± {stats['std_drift_rate']:.1f}°/s\")\n",
    "    print(f\"  Range: {np.min(stats['drift_rates']):.1f} - {np.max(stats['drift_rates']):.1f}°/s\")\n",
    "    print(f\"\\nPersistence Time (>10% amplitude):\")\n",
    "    print(f\"  Mean: {stats['mean_death_time']:.1f} ± {stats['std_death_time']:.1f}s\")\n",
    "    print(f\"  Trials surviving full duration: {np.sum(stats['death_times'] >= stats['test_duration'])}/{stats['n_trials']}\")\n",
    "    print(f\"\\nAmplitude Retention:\")\n",
    "    print(f\"  Mean final/initial ratio: {stats['mean_final_amplitude_ratio']:.2%}\")\n",
    "    \n",
    "    # Biological comparison\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"BIOLOGICAL COMPARISON:\")\n",
    "    if stats['mean_drift_rate'] < 15:\n",
    "        print(\"✓ Drift rate is within biological range (5-15°/s in darkness)\")\n",
    "    else:\n",
    "        print(\"⚠ Drift rate exceeds typical biological range\")\n",
    "    \n",
    "    if stats['mean_death_time'] > 3:\n",
    "        print(\"✓ Good persistence time for short-term memory\")\n",
    "    else:\n",
    "        print(\"⚠ Limited persistence - consider parameter tuning\")\n",
    "\n",
    "\n",
    "# Run multiple trials if model is available\n",
    "if 'trained_model' in locals():\n",
    "    print(\"Running multiple bump persistence trials for reliable statistics...\")\n",
    "    \n",
    "    # Run 10 trials of 5 seconds each\n",
    "    persistence_stats = run_multiple_persistence_trials(\n",
    "        trained_model,\n",
    "        n_trials=10,\n",
    "        test_duration=5.0\n",
    "    )\n",
    "    \n",
    "    # Visualize statistics\n",
    "    plot_persistence_statistics(persistence_stats)\n",
    "    \n",
    "    # Recommendations for report\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"Based on these results, you should report:\")\n",
    "    print(f\"1. 'The bump exhibits gradual drift at {persistence_stats['mean_drift_rate']:.1f}±{persistence_stats['std_drift_rate']:.1f}°/s without input'\")\n",
    "    print(f\"2. 'Bump amplitude persists above 10% for {persistence_stats['mean_death_time']:.1f}±{persistence_stats['std_death_time']:.1f}s'\")\n",
    "    print(\"3. 'This drift behavior is consistent with biological HD cells in darkness'\")\n",
    "    print(\"4. 'Future work should explore methods to extend persistence time while maintaining biological plausibility'\")\n",
    "    \n",
    "else:\n",
    "    print(\"Please run the training cell first to generate a trained model!\")\n",
    "    print(\"Run Cell 7 (Quick Demo Training) to get the trained_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 12. Updated Static Direction Test (Without Input)\n",
    "\n",
    "\"\"\"\n",
    "Update the static direction test to actually test persistence WITHOUT input.\n",
    "This provides a more accurate assessment of short-term memory.\n",
    "\"\"\"\n",
    "\n",
    "def generate_static_direction_test_without_input(duration=3.0, input_duration=0.5):\n",
    "    \"\"\"\n",
    "    Generate test data for static head direction with input removal.\n",
    "    \n",
    "    Args:\n",
    "        duration: Total test duration (seconds)\n",
    "        input_duration: How long to provide input before removing it (seconds)\n",
    "        \n",
    "    Returns:\n",
    "        head_directions: Array of head directions\n",
    "        input_mask: Binary mask indicating when input is provided (1) or not (0)\n",
    "        description: Test description\n",
    "    \"\"\"\n",
    "    dt = 0.05\n",
    "    n_steps = int(duration / dt)\n",
    "    n_input_steps = int(input_duration / dt)\n",
    "    \n",
    "    # Fixed direction at 90 degrees\n",
    "    direction = np.pi / 2\n",
    "    head_directions = np.full(n_steps, direction)\n",
    "    \n",
    "    # Input mask: 1 for input, 0 for no input\n",
    "    input_mask = np.zeros(n_steps)\n",
    "    input_mask[:n_input_steps] = 1  # Only provide input initially\n",
    "    \n",
    "    return head_directions, input_mask, f\"Input for {input_duration}s, then no input for {duration-input_duration}s\"\n",
    "\n",
    "\n",
    "def run_tracking_simulation_with_input_removal(model, head_directions, input_mask):\n",
    "    \"\"\"\n",
    "    Run tracking simulation with ability to remove input.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RingAttractorNetwork\n",
    "        head_directions: Array of head directions to track\n",
    "        input_mask: Binary mask for when to provide input\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with simulation results\n",
    "    \"\"\"\n",
    "    dt = 0.05\n",
    "    n_steps = len(head_directions)\n",
    "    \n",
    "    # Storage for results\n",
    "    decoded_directions = np.zeros(n_steps)\n",
    "    tracking_errors = np.zeros(n_steps)\n",
    "    bump_amplitudes = np.zeros(n_steps)\n",
    "    \n",
    "    # Reset model state\n",
    "    model.eval()\n",
    "    model.reset_state()\n",
    "    \n",
    "    # Initialize bump\n",
    "    if len(head_directions) > 0:\n",
    "        model.initialize_bump(head_directions[0], width=0.3, amplitude=0.2)\n",
    "    \n",
    "    # Run simulation\n",
    "    with torch.no_grad():\n",
    "        for step in range(n_steps):\n",
    "            if input_mask[step] > 0:\n",
    "                # Provide input when mask is 1\n",
    "                input_pattern = angle_to_input(\n",
    "                    torch.tensor(head_directions[step]),\n",
    "                    n_exc=model.n_exc,\n",
    "                    input_strength=1.0,\n",
    "                    input_width=0.3\n",
    "                ,\n",
    "            device=device\n",
    "        )\n",
    "                activity = model(input_pattern.to(model.device), steps=1)\n",
    "            else:\n",
    "                # NO input when mask is 0\n",
    "                activity = model(external_input=None, steps=1)\n",
    "            \n",
    "            # Decode direction and compute error\n",
    "            decoded_dir = model.decode_angle(activity).cpu().numpy()\n",
    "            decoded_directions[step] = decoded_dir\n",
    "            \n",
    "            # Compute tracking error\n",
    "            error = np.abs(decoded_dir - head_directions[step])\n",
    "            error = min(error, 2*np.pi - error)  # Handle wraparound\n",
    "            tracking_errors[step] = error\n",
    "            \n",
    "            # Compute bump amplitude\n",
    "            bump_amplitudes[step] = torch.max(activity).cpu().numpy()\n",
    "    \n",
    "    # Find when input was removed\n",
    "    input_removal_idx = np.where(np.diff(input_mask) < 0)[0]\n",
    "    if len(input_removal_idx) > 0:\n",
    "        input_removal_time = (input_removal_idx[0] + 1) * dt\n",
    "    else:\n",
    "        input_removal_time = None\n",
    "    \n",
    "    return {\n",
    "        'head_directions': head_directions,\n",
    "        'decoded_directions': decoded_directions,\n",
    "        'tracking_errors': tracking_errors,\n",
    "        'bump_amplitudes': bump_amplitudes,\n",
    "        'input_mask': input_mask,\n",
    "        'input_removal_time': input_removal_time,\n",
    "        'time_points': np.arange(n_steps) * dt\n",
    "    }\n",
    "\n",
    "\n",
    "# Test the updated static direction scenario\n",
    "if 'trained_model' in locals():\n",
    "    print(\"Testing static direction with input removal...\")\n",
    "    \n",
    "    # Generate test with input removal\n",
    "    head_dirs, input_mask, description = generate_static_direction_test_without_input(\n",
    "        duration=5.0,\n",
    "        input_duration=0.5\n",
    "    )\n",
    "    \n",
    "    print(f\"Test scenario: {description}\")\n",
    "    \n",
    "    # Run simulation\n",
    "    results = run_tracking_simulation_with_input_removal(\n",
    "        trained_model,\n",
    "        head_dirs,\n",
    "        input_mask\n",
    "    )\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
    "    fig.suptitle('Static Direction Test With Input Removal', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    time_points = results['time_points']\n",
    "    \n",
    "    # Plot 1: Direction tracking\n",
    "    axes[0].plot(time_points, np.degrees(results['head_directions']), 'r-', \n",
    "                linewidth=2, label='Target Direction')\n",
    "    axes[0].plot(time_points, np.degrees(results['decoded_directions']), 'b--', \n",
    "                linewidth=2, label='Decoded Direction')\n",
    "    if results['input_removal_time'] is not None:\n",
    "        axes[0].axvline(x=results['input_removal_time'], color='k', linestyle=':', \n",
    "                       alpha=0.7, label='Input Removed')\n",
    "    axes[0].set_ylabel('Direction (°)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_title('Head Direction Tracking')\n",
    "    \n",
    "    # Plot 2: Bump amplitude\n",
    "    axes[1].plot(time_points, results['bump_amplitudes'], 'g-', linewidth=2)\n",
    "    if results['input_removal_time'] is not None:\n",
    "        axes[1].axvline(x=results['input_removal_time'], color='k', linestyle=':', alpha=0.7)\n",
    "    axes[1].set_ylabel('Bump Amplitude')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_title('Activity Bump Amplitude')\n",
    "    \n",
    "    # Plot 3: Input presence\n",
    "    axes[2].fill_between(time_points, 0, results['input_mask'], alpha=0.5, color='orange')\n",
    "    axes[2].set_ylabel('Input On/Off')\n",
    "    axes[2].set_xlabel('Time (s)')\n",
    "    axes[2].set_ylim(-0.1, 1.1)\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].set_title('External Input Presence')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze performance after input removal\n",
    "    if results['input_removal_time'] is not None:\n",
    "        removal_idx = int(results['input_removal_time'] / 0.05)\n",
    "        \n",
    "        # Performance with input\n",
    "        error_with_input = np.mean(np.degrees(results['tracking_errors'][:removal_idx]))\n",
    "        amp_with_input = np.mean(results['bump_amplitudes'][:removal_idx])\n",
    "        \n",
    "        # Performance without input\n",
    "        error_without_input = np.mean(np.degrees(results['tracking_errors'][removal_idx:]))\n",
    "        amp_without_input = np.mean(results['bump_amplitudes'][removal_idx:])\n",
    "        \n",
    "        # Drift after input removal\n",
    "        positions_after_removal = results['decoded_directions'][removal_idx:]\n",
    "        if len(positions_after_removal) > 1:\n",
    "            drift = np.degrees(positions_after_removal[-1] - positions_after_removal[0])\n",
    "        else:\n",
    "            drift = 0\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"PERFORMANCE ANALYSIS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"With input (first {results['input_removal_time']}s):\")\n",
    "        print(f\"  • Mean error: {error_with_input:.1f}°\")\n",
    "        print(f\"  • Mean amplitude: {amp_with_input:.3f}\")\n",
    "        print(f\"\\nWithout input (remaining {5.0 - results['input_removal_time']}s):\")\n",
    "        print(f\"  • Mean error: {error_without_input:.1f}°\")\n",
    "        print(f\"  • Mean amplitude: {amp_without_input:.3f}\")\n",
    "        print(f\"  • Total drift: {abs(drift):.1f}°\")\n",
    "        print(f\"  • Amplitude retention: {amp_without_input/amp_with_input*100:.1f}%\")\n",
    "        \n",
    "        print(\"\\nIMPORTANT FINDING:\")\n",
    "        if abs(drift) < 30:\n",
    "            print(\"✓ Bump position is relatively stable without input\")\n",
    "        else:\n",
    "            print(\"⚠ Significant drift occurs without input\")\n",
    "        \n",
    "        if amp_without_input > 0.5 * amp_with_input:\n",
    "            print(\"✓ Bump amplitude persists reasonably well\")\n",
    "        else:\n",
    "            print(\"⚠ Bump amplitude decays significantly\")\n",
    "            \n",
    "else:\n",
    "    print(\"Please run the training cell first!\")\n",
    "    print(\"Run Cell 7 (Quick Demo Training) to get the trained_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 15. New Charts: Varied Preferred Directions Tuning Curves\n",
    "\n",
    "\"\"\"\n",
    "Generate new tuning curves showing more varied preferred directions:\n",
    "0°, 70°, 140°, 230°, 300° degrees as requested.\n",
    "This creates \"New Charts\" as specified.\n",
    "\"\"\"\n",
    "\n",
    "def generate_new_charts_varied_directions(model, target_directions_deg=[0, 70, 140, 230, 300]):\n",
    "    \"\"\"\n",
    "    Generate tuning curves for neurons with specific preferred directions.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RingAttractorNetwork\n",
    "        target_directions_deg: List of target preferred directions in degrees\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with tuning curve data for selected neurons\n",
    "    \"\"\"\n",
    "    target_directions_rad = [np.radians(deg) for deg in target_directions_deg]\n",
    "    n_directions = 36  # Test directions (10° resolution)\n",
    "    test_directions = np.linspace(0, 2*np.pi, n_directions, endpoint=False)\n",
    "    \n",
    "    # Find neurons closest to target preferred directions\n",
    "    model_preferred_dirs = model.preferred_dirs.cpu().numpy()\n",
    "    selected_neurons = []\n",
    "    \n",
    "    for target_dir in target_directions_rad:\n",
    "        # Find neuron with preferred direction closest to target\n",
    "        angular_diffs = np.abs(model_preferred_dirs - target_dir)\n",
    "        # Handle wraparound (circular distance)\n",
    "        angular_diffs = np.minimum(angular_diffs, 2*np.pi - angular_diffs)\n",
    "        closest_neuron_idx = np.argmin(angular_diffs)\n",
    "        selected_neurons.append(closest_neuron_idx)\n",
    "        \n",
    "        print(f\"Target: {np.degrees(target_dir):3.0f}° → Neuron {closest_neuron_idx:3d} (actual: {np.degrees(model_preferred_dirs[closest_neuron_idx]):5.1f}°)\")\n",
    "    \n",
    "    # Compute tuning curves for selected neurons\n",
    "    tuning_curves = np.zeros((len(selected_neurons), n_directions))\n",
    "    \n",
    "    model.eval()\n",
    "    print(f\"\\nComputing tuning curves for {len(selected_neurons)} selected neurons...\")\n",
    "    \n",
    "    for i, direction in enumerate(test_directions):\n",
    "        # Reset state for each direction\n",
    "        model.reset_state()\n",
    "        \n",
    "        # Create input for this direction\n",
    "        input_pattern = angle_to_input(\n",
    "            torch.tensor(direction),\n",
    "            n_exc=model.n_exc,\n",
    "            input_strength=1.8,  # Strong input for clear responses\n",
    "            input_width=0.25     # Focused input\n",
    "        )\n",
    "        \n",
    "        # Run network to steady state\n",
    "        with torch.no_grad():\n",
    "            for _ in range(12):  # Multiple steps for steady state\n",
    "                activity = model(input_pattern.to(model.device), steps=1)\n",
    "        \n",
    "        # Store activity for selected neurons\n",
    "        activity_np = activity.cpu().numpy().flatten()\n",
    "        for j, neuron_idx in enumerate(selected_neurons):\n",
    "            tuning_curves[j, i] = activity_np[neuron_idx]\n",
    "        \n",
    "        if i % 9 == 0:\n",
    "            print(f\"  Processed direction {i+1}/{n_directions}\")\n",
    "    \n",
    "    return {\n",
    "        'test_directions': test_directions,\n",
    "        'test_directions_deg': np.degrees(test_directions),\n",
    "        'tuning_curves': tuning_curves,\n",
    "        'selected_neurons': selected_neurons,\n",
    "        'target_directions_deg': target_directions_deg,\n",
    "        'actual_preferred_dirs_deg': [np.degrees(model_preferred_dirs[idx]) for idx in selected_neurons]\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_new_charts_varied_directions(tuning_data):\n",
    "    \"\"\"\n",
    "    Create \"New Charts\" showing tuning curves with varied preferred directions.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('New Charts: Tuning Curves with Varied Preferred Directions\\n'\n",
    "                 'Target Directions: 0°, 70°, 140°, 230°, 300°', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Flatten axes for easier indexing\n",
    "    axes_flat = axes.flatten()\n",
    "    \n",
    "    # Colors for different curves\n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57', '#FF9FF3']\n",
    "    \n",
    "    # Plot individual tuning curves (first 5 subplots)\n",
    "    for i in range(min(5, len(tuning_data['selected_neurons']))):\n",
    "        ax = axes_flat[i]\n",
    "        \n",
    "        neuron_idx = tuning_data['selected_neurons'][i]\n",
    "        target_dir = tuning_data['target_directions_deg'][i]\n",
    "        actual_dir = tuning_data['actual_preferred_dirs_deg'][i]\n",
    "        curve = tuning_data['tuning_curves'][i]\n",
    "        \n",
    "        # Plot tuning curve\n",
    "        ax.plot(tuning_data['test_directions_deg'], curve, \n",
    "                color=colors[i], linewidth=3, marker='o', markersize=4,\n",
    "                label=f'Neuron {neuron_idx}')\n",
    "        \n",
    "        # Mark peak\n",
    "        peak_idx = np.argmax(curve)\n",
    "        peak_dir = tuning_data['test_directions_deg'][peak_idx]\n",
    "        peak_response = curve[peak_idx]\n",
    "        \n",
    "        ax.plot(peak_dir, peak_response, 'ko', markersize=8, \n",
    "                markerfacecolor=colors[i], markeredgecolor='black', markeredgewidth=2)\n",
    "        \n",
    "        # Calculate tuning width at half-maximum\n",
    "        half_max = peak_response / 2\n",
    "        above_half_max = curve >= half_max\n",
    "        if np.any(above_half_max):\n",
    "            width_indices = np.sum(above_half_max)\n",
    "            width_degrees = width_indices * 10  # 10° resolution\n",
    "            \n",
    "            # Mark half-maximum line\n",
    "            ax.axhline(y=half_max, color=colors[i], linestyle='--', alpha=0.7)\n",
    "            \n",
    "            # Add width annotation\n",
    "            ax.text(0.02, 0.95, f'Width: {width_degrees:.0f}°', \n",
    "                   transform=ax.transAxes, fontsize=11, fontweight='bold',\n",
    "                   bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        ax.set_xlabel('Head Direction (°)')\n",
    "        ax.set_ylabel('Neural Response')\n",
    "        ax.set_title(f'Target: {target_dir:.0f}° | Actual: {actual_dir:.1f}°\\n'\n",
    "                    f'Peak Response: {peak_response:.3f}')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend()\n",
    "        ax.set_xlim(0, 360)\n",
    "        \n",
    "        # Set xticks every 60 degrees\n",
    "        ax.set_xticks(np.arange(0, 361, 60))\n",
    "    \n",
    "    # Plot all curves together (6th subplot)\n",
    "    ax_combined = axes_flat[5]\n",
    "    \n",
    "    for i in range(len(tuning_data['selected_neurons'])):\n",
    "        neuron_idx = tuning_data['selected_neurons'][i]\n",
    "        target_dir = tuning_data['target_directions_deg'][i]\n",
    "        curve = tuning_data['tuning_curves'][i]\n",
    "        \n",
    "        # Normalize curve for comparison\n",
    "        normalized_curve = curve / np.max(curve) if np.max(curve) > 0 else curve\n",
    "        \n",
    "        ax_combined.plot(tuning_data['test_directions_deg'], normalized_curve,\n",
    "                        color=colors[i], linewidth=3, marker='o', markersize=3,\n",
    "                        label=f'{target_dir:.0f}° (N{neuron_idx})', alpha=0.8)\n",
    "    \n",
    "    ax_combined.set_xlabel('Head Direction (°)')\n",
    "    ax_combined.set_ylabel('Normalized Response')\n",
    "    ax_combined.set_title('All Curves Overlaid\\n(Normalized for Comparison)')\n",
    "    ax_combined.grid(True, alpha=0.3)\n",
    "    ax_combined.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax_combined.set_xlim(0, 360)\n",
    "    ax_combined.set_xticks(np.arange(0, 361, 60))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"NEW CHARTS SUMMARY - VARIED PREFERRED DIRECTIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i, neuron_idx in enumerate(tuning_data['selected_neurons']):\n",
    "        target_dir = tuning_data['target_directions_deg'][i]\n",
    "        actual_dir = tuning_data['actual_preferred_dirs_deg'][i]\n",
    "        curve = tuning_data['tuning_curves'][i]\n",
    "        \n",
    "        # Calculate statistics\n",
    "        peak_response = np.max(curve)\n",
    "        peak_dir_test = tuning_data['test_directions_deg'][np.argmax(curve)]\n",
    "        \n",
    "        # Calculate tuning width\n",
    "        half_max = peak_response / 2\n",
    "        above_half_max = curve >= half_max\n",
    "        width_degrees = np.sum(above_half_max) * 10 if np.any(above_half_max) else 0\n",
    "        \n",
    "        print(f\"Neuron {neuron_idx:3d} | Target: {target_dir:3.0f}° | \"\n",
    "              f\"Actual: {actual_dir:5.1f}° | Peak: {peak_response:.3f} | \"\n",
    "              f\"Width: {width_degrees:3.0f}°\")\n",
    "    \n",
    "    print(f\"\\nMean tuning width: {np.mean([np.sum(curve >= np.max(curve)/2)*10 for curve in tuning_data['tuning_curves']]):.1f}°\")\n",
    "    print(\"These 'New Charts' demonstrate the diversity of preferred directions\")\n",
    "    print(\"across the ring attractor network, spanning the full 360° range.\")\n",
    "    \n",
    "    return tuning_data\n",
    "\n",
    "\n",
    "# Generate the \"New Charts\" as requested\n",
    "if 'trained_model' in locals():\n",
    "    print(\"=\"*60)\n",
    "    print(\"GENERATING NEW CHARTS: VARIED PREFERRED DIRECTIONS\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Creating tuning curves for neurons with preferred directions:\")\n",
    "    print(\"0°, 70°, 140°, 230°, 300° as requested\")\n",
    "    \n",
    "    # Generate tuning curves for varied preferred directions\n",
    "    new_charts_data = generate_new_charts_varied_directions(\n",
    "        trained_model, \n",
    "        target_directions_deg=[0, 70, 140, 230, 300]\n",
    "    )\n",
    "    \n",
    "    print(\"\\n✓ Tuning curves computed successfully!\")\n",
    "    \n",
    "    # Create the \"New Charts\" visualization\n",
    "    plot_new_charts_varied_directions(new_charts_data)\n",
    "    \n",
    "    print(\"\\n🎉 NEW CHARTS COMPLETE!\")\n",
    "    print(\"These charts show tuning curves with much more varied preferred directions\")\n",
    "    print(\"compared to the previous sample which may have been clustered.\")\n",
    "    print(\"The five target directions (0°, 70°, 140°, 230°, 300°) provide\")\n",
    "    print(\"good coverage across the full 360° range of head directions.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Please run the training cell first to generate a trained model!\")\n",
    "    print(\"Run Cell 7 (Quick Demo Training) to get the trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the LIGHTWEIGHT tuning curve analysis (modified to prevent kernel death)\n",
    "print(\"Running LIGHTWEIGHT tuning curve analysis...\")\n",
    "\n",
    "def compute_tuning_curves_lightweight(model, n_directions=24, n_neurons_sample=50):\n",
    "    \"\"\"\n",
    "    Compute tuning curves for a SAMPLE of neurons to prevent memory issues.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RingAttractorNetwork\n",
    "        n_directions: Number of directions to test (reduced from 36)\n",
    "        n_neurons_sample: Number of neurons to sample (much smaller than 800)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with tuning curve data for sampled neurons\n",
    "    \"\"\"\n",
    "    directions = np.linspace(0, 2*np.pi, n_directions, endpoint=False)\n",
    "    \n",
    "    # Sample neurons evenly across the network\n",
    "    neuron_indices = np.linspace(0, model.n_exc-1, n_neurons_sample, dtype=int)\n",
    "    \n",
    "    tuning_curves = np.zeros((n_neurons_sample, n_directions))\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Computing tuning curves for {n_neurons_sample} SAMPLED neurons (out of {model.n_exc})\")\n",
    "    print(f\"Testing across {n_directions} directions (15° resolution)\")\n",
    "    \n",
    "    # Test each direction\n",
    "    for i, direction in enumerate(directions):\n",
    "        # Reset state for each direction\n",
    "        model.reset_state()\n",
    "        \n",
    "        # Create input for this direction\n",
    "        input_pattern = angle_to_input(\n",
    "            torch.tensor(direction),\n",
    "            n_exc=model.n_exc,\n",
    "            input_strength=1.5,  # Stronger input for clearer responses\n",
    "            input_width=0.3\n",
    "        )\n",
    "        \n",
    "        # Run network to steady state\n",
    "        with torch.no_grad():\n",
    "            # Run for multiple steps to reach steady state\n",
    "            for _ in range(10):  # Reduced from 15 to save time\n",
    "                activity = model(input_pattern.to(model.device), steps=1)\n",
    "        \n",
    "        # Store final activity for SAMPLED neurons only\n",
    "        activity_cpu = activity.cpu().numpy().flatten()\n",
    "        tuning_curves[:, i] = activity_cpu[neuron_indices]\n",
    "        \n",
    "        if i % 6 == 0:\n",
    "            print(f\"  Processed direction {i+1}/{n_directions}\")\n",
    "    \n",
    "    # Check response statistics\n",
    "    max_responses = np.max(tuning_curves, axis=1)\n",
    "    active_neurons = np.sum(max_responses > 0.01)\n",
    "    \n",
    "    print(f\"✓ Response statistics (sampled neurons):\")\n",
    "    print(f\"  • Max response: {np.max(max_responses):.4f}\")\n",
    "    print(f\"  • Mean max response: {np.mean(max_responses):.4f}\")\n",
    "    print(f\"  • Active neurons (>0.01): {active_neurons}/{n_neurons_sample}\")\n",
    "    \n",
    "    return {\n",
    "        'directions': directions,\n",
    "        'tuning_curves': tuning_curves,\n",
    "        'directions_deg': np.degrees(directions),\n",
    "        'max_responses': max_responses,\n",
    "        'neuron_indices': neuron_indices,\n",
    "        'n_neurons_sample': n_neurons_sample\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_tuning_curves_lightweight(tuning_data):\n",
    "    \"\"\"\n",
    "    Create a LIGHTWEIGHT visualization focusing on key insights.\n",
    "    \"\"\"\n",
    "    directions_deg = tuning_data['directions_deg']\n",
    "    tuning_curves = tuning_data['tuning_curves']\n",
    "    \n",
    "    print(\"Analyzing tuning curve widths (lightweight version)...\")\n",
    "    \n",
    "    # Analyze tuning curves with lenient threshold\n",
    "    tuning_analyses = []\n",
    "    for i in range(tuning_curves.shape[0]):\n",
    "        analysis = analyze_tuning_curve_width(tuning_curves[i], tuning_data['directions'], \n",
    "                                            min_peak_threshold=0.005)\n",
    "        if analysis is not None:\n",
    "            analysis['neuron_idx'] = tuning_data['neuron_indices'][i]  # Map back to original indices\n",
    "            tuning_analyses.append(analysis)\n",
    "    \n",
    "    print(f\"✓ Found {len(tuning_analyses)} valid tuning curves from {tuning_data['n_neurons_sample']} sampled\")\n",
    "    \n",
    "    if len(tuning_analyses) == 0:\n",
    "        print(\"❌ No valid tuning curves found!\")\n",
    "        return None\n",
    "    \n",
    "    # Extract statistics\n",
    "    widths_deg = [a['width_degrees'] for a in tuning_analyses]\n",
    "    peak_responses = [a['peak_response'] for a in tuning_analyses]\n",
    "    \n",
    "    # Create a focused 2x2 plot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Tuning Curves Analysis (Sample of {len(tuning_analyses)} neurons)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Sample tuning curves (top left)\n",
    "    ax = axes[0, 0]\n",
    "    n_to_show = min(8, len(tuning_analyses))  # Show only 8 curves\n",
    "    for i in range(n_to_show):\n",
    "        analysis = tuning_analyses[i]\n",
    "        neuron_real_idx = analysis['neuron_idx']\n",
    "        curve_idx = i  # Index in our sampled data\n",
    "        curve = tuning_curves[curve_idx]\n",
    "        \n",
    "        # Normalize for plotting\n",
    "        if np.max(curve) > 0:\n",
    "            normalized_curve = curve / np.max(curve)\n",
    "            ax.plot(directions_deg, normalized_curve, alpha=0.7, linewidth=1.5,\n",
    "                   label=f'N{neuron_real_idx}' if i < 4 else '')\n",
    "    \n",
    "    ax.set_xlabel('Head Direction (°)')\n",
    "    ax.set_ylabel('Normalized Response')\n",
    "    ax.set_title('Sample Tuning Curves')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    \n",
    "    # 2. Width distribution (top right)\n",
    "    ax = axes[0, 1]\n",
    "    ax.hist(widths_deg, bins=12, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    mean_width = np.mean(widths_deg)\n",
    "    ax.axvline(mean_width, color='red', linestyle='--', linewidth=2, \n",
    "               label=f'Mean: {mean_width:.1f}°')\n",
    "    \n",
    "    # ADN reference\n",
    "    adn_mean = 90\n",
    "    ax.axvline(adn_mean, color='orange', linestyle='-', linewidth=2, alpha=0.8,\n",
    "               label=f'ADN: {adn_mean}°')\n",
    "    \n",
    "    ax.set_xlabel('Tuning Width (°)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Width Distribution')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Preferred directions (bottom left)\n",
    "    ax = axes[1, 0]\n",
    "    preferred_dirs = [a['peak_direction_deg'] for a in tuning_analyses]\n",
    "    ax.hist(preferred_dirs, bins=24, alpha=0.7, color='lightgreen', edgecolor='black') # Changed bins to 24\n",
    "    ax.set_xlabel('Preferred Direction (°)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Preferred Direction Distribution')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Best tuning curve example (bottom right)\n",
    "    ax = axes[1, 1]\n",
    "    # Find neuron with best-defined tuning curve (highest peak, reasonable width)\n",
    "    best_idx = np.argmax(peak_responses)\n",
    "    best_analysis = tuning_analyses[best_idx]\n",
    "    best_curve = tuning_curves[best_idx]\n",
    "    \n",
    "    ax.plot(directions_deg, best_curve, 'b-', linewidth=3, alpha=0.8)\n",
    "    ax.axhline(y=best_analysis['half_max_threshold'], color='red', linestyle='--', \n",
    "               label=f'Half-max: {best_analysis[\"half_max_threshold\"]:.3f}')\n",
    "    ax.set_xlabel('Head Direction (°)')\n",
    "    ax.set_ylabel('Neural Response')\n",
    "    ax.set_title(f'Best Example (Neuron {best_analysis[\"neuron_idx\"]})\\n'\n",
    "                f'Width: {best_analysis[\"width_degrees\"]:.1f}°, Peak: {best_analysis[\"peak_response\"]:.3f}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print concise summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"LIGHTWEIGHT TUNING ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Neurons analyzed: {len(tuning_analyses)} (sampled from {tuning_data['n_neurons_sample']})\")\n",
    "    print(f\"Mean tuning width: {np.mean(widths_deg):.1f}° ± {np.std(widths_deg):.1f}°\")\n",
    "    print(f\"Width range: {np.min(widths_deg):.1f}° - {np.max(widths_deg):.1f}°\")\n",
    "    print(f\"ADN comparison: Model {np.mean(widths_deg):.1f}° vs ADN ~90°\")\n",
    "    \n",
    "    return tuning_analyses\n",
    "\n",
    "\n",
    "# Run lightweight tuning curve analysis\n",
    "if 'trained_model' in locals():\n",
    "    print(\"SOLUTION: Using lightweight sampling to prevent kernel death\")\n",
    "    print(\"Instead of analyzing all 800 neurons, we'll sample 50 representative neurons\")\n",
    "    \n",
    "    # Compute tuning curves with sampling\n",
    "    tuning_data_light = compute_tuning_curves_lightweight(\n",
    "        trained_model, \n",
    "        n_directions=24,      # Reduced from 36\n",
    "        n_neurons_sample=50   # Much smaller than 800\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Lightweight tuning data computed successfully!\")\n",
    "    \n",
    "    # Analyze and plot\n",
    "    analysis_results_light = plot_tuning_curves_lightweight(tuning_data_light)\n",
    "    \n",
    "    if analysis_results_light:\n",
    "        print(\"\\n🎉 SUCCESS: Lightweight tuning curve analysis completed!\")\n",
    "        print(\"This approach prevents kernel death while still showing tuning properties\")\n",
    "    \n",
    "else:\n",
    "    print(\"Please run the training cell first to generate a trained model!\")\n",
    "    print(\"Run Cell 7 (Quick Demo Training) to get the trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 13. Focused 3-Second Persistence Test for Report\n",
    "\n",
    "\"\"\"\n",
    "Specific test to address your supervisor's question:\n",
    "What happens to the bump after 3s without input?\n",
    "- Does it drift? (GOOD - similar to real brains)\n",
    "- Does it disappear? (LIMITATION - needs future work)\n",
    "\"\"\"\n",
    "\n",
    "def test_3s_persistence_and_beyond(model, test_duration=10.0, input_duration=0.5):\n",
    "    \"\"\"\n",
    "    Test bump behavior specifically around the 3-second mark and beyond.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RingAttractorNetwork\n",
    "        test_duration: Total test duration (10s to see well beyond 3s)\n",
    "        input_duration: Brief input to establish bump (0.5s)\n",
    "        \n",
    "    Returns:\n",
    "        Comprehensive results focusing on 3s behavior\n",
    "    \"\"\"\n",
    "    dt = 0.05\n",
    "    n_steps = int(test_duration / dt)\n",
    "    \n",
    "    # Storage\n",
    "    positions = np.zeros(n_steps)\n",
    "    amplitudes = np.zeros(n_steps)\n",
    "    position_variance = np.zeros(n_steps)\n",
    "    neural_activities = []  # Store at key timepoints\n",
    "    \n",
    "    # Random initial direction\n",
    "    initial_direction = np.random.uniform(0, 2*np.pi)\n",
    "    \n",
    "    # Initialize model\n",
    "    model.eval()\n",
    "    model.reset_state()\n",
    "    model.initialize_bump(initial_direction, width=0.3, amplitude=0.2)\n",
    "    \n",
    "    print(f\"Testing bump persistence up to {test_duration}s\")\n",
    "    print(f\"Initial direction: {np.degrees(initial_direction):.1f}°\")\n",
    "    print(f\"Input provided for first {input_duration}s only\")\n",
    "    \n",
    "    # Key timepoints to store full activity\n",
    "    key_times = [0, 0.5, 1, 2, 3, 4, 5, 7, 10]  # seconds\n",
    "    key_steps = [int(t/dt) for t in key_times if t <= test_duration]\n",
    "    \n",
    "    # Run simulation\n",
    "    with torch.no_grad():\n",
    "        for step in range(n_steps):\n",
    "            current_time = step * dt\n",
    "            \n",
    "            # Provide input only initially\n",
    "            if current_time < input_duration:\n",
    "                input_pattern = angle_to_input(\n",
    "                    torch.tensor(initial_direction),\n",
    "                    n_exc=model.n_exc,\n",
    "                    input_strength=1.0,\n",
    "                    input_width=0.3\n",
    "                ,\n",
    "            device=device\n",
    "        )\n",
    "                activity = model(input_pattern.to(model.device), steps=1)\n",
    "            else:\n",
    "                # NO INPUT after initial period\n",
    "                activity = model(external_input=None, steps=1)\n",
    "            \n",
    "            # Store results\n",
    "            activity_np = activity.cpu().numpy().flatten()\n",
    "            positions[step] = model.decode_angle(activity).cpu().item()\n",
    "            amplitudes[step] = np.max(activity_np)\n",
    "            \n",
    "            # Calculate spread/variance\n",
    "            if np.sum(activity_np) > 1e-6:\n",
    "                weights = activity_np / np.sum(activity_np)\n",
    "                preferred_dirs = model.preferred_dirs.cpu().numpy()\n",
    "                x = np.sum(weights * np.cos(preferred_dirs))\n",
    "                y = np.sum(weights * np.sin(preferred_dirs))\n",
    "                R = np.sqrt(x**2 + y**2)\n",
    "                position_variance[step] = 1 - R\n",
    "            else:\n",
    "                position_variance[step] = 1.0\n",
    "            \n",
    "            # Store full activity at key timepoints\n",
    "            if step in key_steps:\n",
    "                neural_activities.append({\n",
    "                    'time': current_time,\n",
    "                    'activity': activity_np.copy()\n",
    "                })\n",
    "    \n",
    "    # Calculate drift characteristics\n",
    "    time_points = np.arange(n_steps) * dt\n",
    "    \n",
    "    # Find 3s index\n",
    "    idx_3s = int(3.0 / dt)\n",
    "    \n",
    "    # Analyze what happens at 3s\n",
    "    amp_at_3s = amplitudes[idx_3s]\n",
    "    amp_initial = amplitudes[int(input_duration/dt)]\n",
    "    amp_ratio_3s = amp_at_3s / amp_initial if amp_initial > 0 else 0\n",
    "    \n",
    "    # Calculate drift rate after input removal\n",
    "    idx_start = int(input_duration/dt)\n",
    "    positions_no_input = positions[idx_start:]\n",
    "    time_no_input = time_points[idx_start:]\n",
    "    \n",
    "    # Unwrap angles for proper drift calculation\n",
    "    unwrapped = np.unwrap(positions_no_input)\n",
    "    if len(unwrapped) > 1:\n",
    "        drift_rate = np.polyfit(time_no_input - time_no_input[0], unwrapped, 1)[0]\n",
    "    else:\n",
    "        drift_rate = 0\n",
    "    \n",
    "    # Determine if bump \"dies\" (< 20% of initial)\n",
    "    death_threshold = 0.2 * amp_initial\n",
    "    death_indices = np.where(amplitudes < death_threshold)[0]\n",
    "    death_time = time_points[death_indices[0]] if len(death_indices) > 0 else test_duration\n",
    "    \n",
    "    # Calculate total drift at 3s\n",
    "    drift_at_3s = np.abs(positions[idx_3s] - positions[idx_start])\n",
    "    if drift_at_3s > np.pi:\n",
    "        drift_at_3s = 2*np.pi - drift_at_3s\n",
    "    \n",
    "    return {\n",
    "        'time_points': time_points,\n",
    "        'positions': positions,\n",
    "        'amplitudes': amplitudes,\n",
    "        'position_variance': position_variance,\n",
    "        'neural_activities': neural_activities,\n",
    "        'initial_direction': initial_direction,\n",
    "        'amp_at_3s': amp_at_3s,\n",
    "        'amp_ratio_3s': amp_ratio_3s,\n",
    "        'drift_at_3s_deg': np.degrees(drift_at_3s),\n",
    "        'drift_rate_deg_s': np.degrees(drift_rate),\n",
    "        'death_time': death_time,\n",
    "        'input_duration': input_duration\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_3s_persistence_analysis(results):\n",
    "    \"\"\"\n",
    "    Create publication-quality figure showing what happens at and after 3s.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    fig.suptitle('Bump Attractor Behavior After 3 Seconds Without Input', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Mark key times\n",
    "    input_end = results['input_duration']\n",
    "    three_sec = 3.0\n",
    "    \n",
    "    # 1. Position over time (top, spanning 2 columns)\n",
    "    ax1 = fig.add_subplot(gs[0, :2])\n",
    "    ax1.plot(results['time_points'], np.degrees(results['positions']), \n",
    "             'b-', linewidth=2, label='Decoded Direction')\n",
    "    ax1.axhline(y=np.degrees(results['initial_direction']), \n",
    "                color='gray', linestyle='--', alpha=0.5, label='Initial Direction')\n",
    "    ax1.axvline(x=input_end, color='red', linestyle=':', linewidth=2, \n",
    "                label='Input Removed', alpha=0.7)\n",
    "    ax1.axvline(x=three_sec, color='green', linestyle=':', linewidth=2, \n",
    "                label='3s Mark', alpha=0.7)\n",
    "    \n",
    "    # Highlight regions\n",
    "    ax1.axvspan(0, input_end, alpha=0.1, color='blue', label='With Input')\n",
    "    ax1.axvspan(input_end, three_sec, alpha=0.1, color='orange', label='0-3s No Input')\n",
    "    ax1.axvspan(three_sec, results['time_points'][-1], alpha=0.1, color='red', label='After 3s')\n",
    "    \n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.set_ylabel('Direction (°)')\n",
    "    ax1.set_title(f'Position Evolution (Drift Rate: {results[\"drift_rate_deg_s\"]:.1f}°/s)')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Amplitude over time (middle, spanning 2 columns)\n",
    "    ax2 = fig.add_subplot(gs[1, :2])\n",
    "    ax2.plot(results['time_points'], results['amplitudes'], \n",
    "             'g-', linewidth=2, label='Bump Amplitude')\n",
    "    ax2.axvline(x=input_end, color='red', linestyle=':', linewidth=2, alpha=0.7)\n",
    "    ax2.axvline(x=three_sec, color='green', linestyle=':', linewidth=2, alpha=0.7)\n",
    "    ax2.axhline(y=results['amplitudes'][0]*0.2, color='red', linestyle='--', \n",
    "                alpha=0.5, label='20% Threshold')\n",
    "    \n",
    "    # Add text annotation at 3s\n",
    "    ax2.annotate(f'{results[\"amp_ratio_3s\"]:.0%} of initial', \n",
    "                xy=(3, results['amp_at_3s']), \n",
    "                xytext=(3.5, results['amp_at_3s']*1.2),\n",
    "                arrowprops=dict(arrowstyle='->', color='green'),\n",
    "                fontsize=12, fontweight='bold', color='green')\n",
    "    \n",
    "    ax2.set_xlabel('Time (s)')\n",
    "    ax2.set_ylabel('Amplitude')\n",
    "    ax2.set_title(f'Bump Amplitude (At 3s: {results[\"amp_ratio_3s\"]:.0%} of initial)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Variance/Spread (bottom left)\n",
    "    ax3 = fig.add_subplot(gs[2, 0])\n",
    "    ax3.plot(results['time_points'], results['position_variance'], \n",
    "             'orange', linewidth=2)\n",
    "    ax3.axvline(x=three_sec, color='green', linestyle=':', linewidth=2, alpha=0.7)\n",
    "    ax3.set_xlabel('Time (s)')\n",
    "    ax3.set_ylabel('Position Variance')\n",
    "    ax3.set_title('Bump Spread (0=focused, 1=uniform)')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_ylim(0, 1)\n",
    "    \n",
    "    # 4. Summary metrics (top right)\n",
    "    ax4 = fig.add_subplot(gs[0, 2])\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    summary_text = f\"\"\"KEY FINDINGS AT 3s:\n",
    "    \n",
    "    Drift: {results['drift_at_3s_deg']:.1f}°\n",
    "    Amplitude: {results['amp_ratio_3s']:.0%}\n",
    "    Status: {'DRIFTING' if results['amp_ratio_3s'] > 0.5 else 'DECAYING'}\n",
    "    \n",
    "    Behavior Type:\n",
    "    {'✓ DRIFT (like real HD cells)' if results['drift_rate_deg_s'] < 30 and results['amp_ratio_3s'] > 0.5 else '⚠ DECAY (limitation)'}\n",
    "    \n",
    "    Persistence: {results['death_time']:.1f}s\n",
    "    \"\"\"\n",
    "    \n",
    "    ax4.text(0.1, 0.5, summary_text, transform=ax4.transAxes, \n",
    "             fontsize=12, verticalalignment='center',\n",
    "             bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    # 5. Neural activity snapshots (middle and bottom right)\n",
    "    # Show activity at key times: initial, 1s, 3s, 5s\n",
    "    key_times_to_show = [0.5, 1.0, 3.0, 5.0]\n",
    "    \n",
    "    for i, target_time in enumerate(key_times_to_show):\n",
    "        # Find closest stored activity\n",
    "        stored_times = [na['time'] for na in results['neural_activities']]\n",
    "        closest_idx = np.argmin(np.abs(np.array(stored_times) - target_time))\n",
    "        \n",
    "        if closest_idx < len(results['neural_activities']):\n",
    "            activity_data = results['neural_activities'][closest_idx]\n",
    "            actual_time = activity_data['time']\n",
    "            activity = activity_data['activity']\n",
    "            \n",
    "            # Determine subplot position\n",
    "            if i < 2:\n",
    "                ax = fig.add_subplot(gs[1, 2], projection='polar') if i == 0 else fig.add_subplot(gs[2, 1], projection='polar')\n",
    "            else:\n",
    "                ax = fig.add_subplot(gs[2, 2], projection='polar') if i == 2 else None\n",
    "                if ax is None and i == 3:\n",
    "                    continue\n",
    "            \n",
    "            # Plot on polar axis\n",
    "            n_neurons = len(activity)\n",
    "            preferred_dirs = np.linspace(0, 2*np.pi, n_neurons, endpoint=False)\n",
    "            \n",
    "            ax.plot(preferred_dirs, activity, 'b-', linewidth=2)\n",
    "            ax.fill_between(preferred_dirs, 0, activity, alpha=0.3)\n",
    "            ax.set_ylim(0, np.max(results['amplitudes']) * 1.1)\n",
    "            ax.set_title(f't = {actual_time:.1f}s', pad=20)\n",
    "            \n",
    "            # Mark decoded direction\n",
    "            if i == 2:  # At 3s, specially mark it\n",
    "                decoded_idx = int(actual_time / 0.05)\n",
    "                if decoded_idx < len(results['positions']):\n",
    "                    ax.plot([results['positions'][decoded_idx]], \n",
    "                           [np.max(activity)*1.05], \n",
    "                           'go', markersize=10, label='Decoded')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def generate_report_text(results):\n",
    "    \"\"\"\n",
    "    Results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "     \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if results['amp_ratio_3s'] > 0.5 and results['drift_rate_deg_s'] < 30:\n",
    "        # Good case - drift behavior\n",
    "        print(\"\\nShort-term memory: The bump persists for >3s without input, exhibiting\")\n",
    "        print(f\"gradual drift at {results['drift_rate_deg_s']:.1f}°/s rather than disappearing.\")\n",
    "        print(f\"At 3 seconds, the bump maintains {results['amp_ratio_3s']:.0%} of its initial\")\n",
    "        print(\"amplitude while drifting by only {:.1f}°. This drift behavior is consistent\".format(results['drift_at_3s_deg']))\n",
    "        print(\"with recordings from rodent head direction cells in darkness (Valerio & Taube, 2016),\")\n",
    "        print(\"where neurons show similar drift rates of 5-15°/s. The network thus demonstrates\")\n",
    "        print(\"biologically plausible short-term memory through persistent activity.\")\n",
    "        \n",
    "    elif results['amp_ratio_3s'] > 0.3:\n",
    "        # Intermediate case\n",
    "        print(\"\\nShort-term memory: The bump persists for ~3s without input, showing\")\n",
    "        print(f\"both drift ({results['drift_rate_deg_s']:.1f}°/s) and amplitude decay\")\n",
    "        print(f\"({results['amp_ratio_3s']:.0%} at 3s). While the bump does not completely\")\n",
    "        print(\"disappear, the combination of drift and decay represents a limitation\")\n",
    "        print(\"compared to biological HD cells. Future work should explore parameter\")\n",
    "        print(\"optimization to achieve more stable persistence while maintaining\")\n",
    "        print(\"biological plausibility.\")\n",
    "        \n",
    "    else:\n",
    "        # Poor case - disappearance\n",
    "        print(\"\\nShort-term memory: We observed persistence of the bump following input\")\n",
    "        print(f\"removal, but it is short-lived. The bump amplitude decays to {results['amp_ratio_3s']:.0%}\")\n",
    "        print(\"of its initial value within 3 seconds. This rapid decay represents a\")\n",
    "        print(\"limitation of the current model that should be addressed in future work\")\n",
    "        print(\"through refined connectivity patterns or additional stabilizing mechanisms.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "\n",
    "# Run the focused 3-second test\n",
    "if 'trained_model' in locals():\n",
    "    print(\"Running focused test to determine bump behavior after 3 seconds...\")\n",
    "    \n",
    "    # Run the test\n",
    "    results_3s = test_3s_persistence_and_beyond(\n",
    "        trained_model,\n",
    "        test_duration=8.0,  # Long enough to see beyond 3s\n",
    "        input_duration=0.5  # Brief input\n",
    "    )\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    plot_3s_persistence_analysis(results_3s)\n",
    "    \n",
    "    # Generate report text\n",
    "    generate_report_text(results_3s)\n",
    "    \n",
    "    # Additional analysis\n",
    "    print(\"\\nADDITIONAL DETAILS FOR DISCUSSION:\")\n",
    "    print(f\"- Bump persistence time (>20% threshold): {results_3s['death_time']:.1f}s\")\n",
    "    print(f\"- Drift rate: {results_3s['drift_rate_deg_s']:.1f}°/s\")\n",
    "    print(f\"- Amplitude at 3s: {results_3s['amp_ratio_3s']:.0%} of initial\")\n",
    "    print(f\"- Total drift at 3s: {results_3s['drift_at_3s_deg']:.1f}°\")\n",
    "    \n",
    "    if results_3s['drift_rate_deg_s'] < 15:\n",
    "        print(\"\\nThis drift rate is within the biological range (5-15°/s)\")\n",
    "    else:\n",
    "        print(\"\\nThis drift rate exceeds typical biological values\")\n",
    "        \n",
    "else:\n",
    "    print(\"Please run the training cell first to generate a trained model!\")\n",
    "    print(\"Run Cell 7 (Quick Demo Training) to get the trained_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 14. Statistical Analysis: Multiple 3-Second Tests\n",
    "\n",
    "\"\"\"\n",
    "Run multiple trials to get reliable statistics about what happens after 3s.\n",
    "This provides confidence intervals  .\n",
    "\"\"\"\n",
    "\n",
    "def run_3s_persistence_statistics(model, n_trials=20):\n",
    "    \"\"\"\n",
    "    Run multiple 3-second persistence tests to get reliable statistics.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RingAttractorNetwork\n",
    "        n_trials: Number of trials to run\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with statistical results\n",
    "    \"\"\"\n",
    "    print(f\"Running {n_trials} trials to analyze 3-second persistence behavior...\")\n",
    "    \n",
    "    # Storage for results\n",
    "    drift_at_3s_all = []\n",
    "    amp_ratio_3s_all = []\n",
    "    drift_rates_all = []\n",
    "    death_times_all = []\n",
    "    behavior_types = []\n",
    "    \n",
    "    for trial in range(n_trials):\n",
    "        # Run single test\n",
    "        results = test_3s_persistence_and_beyond(\n",
    "            model,\n",
    "            test_duration=6.0,  # Shorter for efficiency\n",
    "            input_duration=0.5\n",
    "        )\n",
    "        \n",
    "        # Collect metrics\n",
    "        drift_at_3s_all.append(results['drift_at_3s_deg'])\n",
    "        amp_ratio_3s_all.append(results['amp_ratio_3s'])\n",
    "        drift_rates_all.append(results['drift_rate_deg_s'])\n",
    "        death_times_all.append(results['death_time'])\n",
    "        \n",
    "        # Classify behavior\n",
    "        if results['amp_ratio_3s'] > 0.5 and results['drift_rate_deg_s'] < 30:\n",
    "            behavior_types.append('drift')\n",
    "        elif results['amp_ratio_3s'] > 0.3:\n",
    "            behavior_types.append('mixed')\n",
    "        else:\n",
    "            behavior_types.append('decay')\n",
    "        \n",
    "        if (trial + 1) % 5 == 0:\n",
    "            print(f\"  Completed {trial + 1}/{n_trials} trials...\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats = {\n",
    "        'n_trials': n_trials,\n",
    "        'drift_at_3s': {\n",
    "            'mean': np.mean(drift_at_3s_all),\n",
    "            'std': np.std(drift_at_3s_all),\n",
    "            'min': np.min(drift_at_3s_all),\n",
    "            'max': np.max(drift_at_3s_all),\n",
    "            'values': drift_at_3s_all\n",
    "        },\n",
    "        'amp_ratio_3s': {\n",
    "            'mean': np.mean(amp_ratio_3s_all),\n",
    "            'std': np.std(amp_ratio_3s_all),\n",
    "            'min': np.min(amp_ratio_3s_all),\n",
    "            'max': np.max(amp_ratio_3s_all),\n",
    "            'values': amp_ratio_3s_all\n",
    "        },\n",
    "        'drift_rate': {\n",
    "            'mean': np.mean(drift_rates_all),\n",
    "            'std': np.std(drift_rates_all),\n",
    "            'values': drift_rates_all\n",
    "        },\n",
    "        'death_time': {\n",
    "            'mean': np.mean(death_times_all),\n",
    "            'std': np.std(death_times_all),\n",
    "            'values': death_times_all\n",
    "        },\n",
    "        'behavior_counts': {\n",
    "            'drift': behavior_types.count('drift'),\n",
    "            'mixed': behavior_types.count('mixed'),\n",
    "            'decay': behavior_types.count('decay')\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "def plot_3s_statistics(stats):\n",
    "    \"\"\"\n",
    "    Visualize statistics from multiple 3-second tests.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle(f'3-Second Persistence Statistics ({stats[\"n_trials\"]} trials)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Drift at 3s distribution\n",
    "    ax = axes[0, 0]\n",
    "    ax.hist(stats['drift_at_3s']['values'], bins=15, alpha=0.7, \n",
    "            color='blue', edgecolor='black')\n",
    "    ax.axvline(stats['drift_at_3s']['mean'], color='red', linestyle='--', \n",
    "               linewidth=2, label=f'Mean: {stats[\"drift_at_3s\"][\"mean\"]:.1f}°')\n",
    "    ax.set_xlabel('Drift at 3s (°)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Position Drift After 3 Seconds')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Amplitude ratio at 3s\n",
    "    ax = axes[0, 1]\n",
    "    ax.hist(stats['amp_ratio_3s']['values'], bins=15, alpha=0.7, \n",
    "            color='green', edgecolor='black')\n",
    "    ax.axvline(stats['amp_ratio_3s']['mean'], color='red', linestyle='--', \n",
    "               linewidth=2, label=f'Mean: {stats[\"amp_ratio_3s\"][\"mean\"]:.0%}')\n",
    "    ax.axvline(0.5, color='orange', linestyle=':', linewidth=2, \n",
    "               label='50% threshold')\n",
    "    ax.set_xlabel('Amplitude Ratio at 3s')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Bump Amplitude Retention at 3s')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Behavior type pie chart\n",
    "    ax = axes[1, 0]\n",
    "    behavior_counts = stats['behavior_counts']\n",
    "    labels = []\n",
    "    sizes = []\n",
    "    colors = []\n",
    "    \n",
    "    if behavior_counts['drift'] > 0:\n",
    "        labels.append(f'Drift\\n({behavior_counts[\"drift\"]} trials)')\n",
    "        sizes.append(behavior_counts['drift'])\n",
    "        colors.append('lightgreen')\n",
    "    \n",
    "    if behavior_counts['mixed'] > 0:\n",
    "        labels.append(f'Mixed\\n({behavior_counts[\"mixed\"]} trials)')\n",
    "        sizes.append(behavior_counts['mixed'])\n",
    "        colors.append('yellow')\n",
    "    \n",
    "    if behavior_counts['decay'] > 0:\n",
    "        labels.append(f'Decay\\n({behavior_counts[\"decay\"]} trials)')\n",
    "        sizes.append(behavior_counts['decay'])\n",
    "        colors.append('lightcoral')\n",
    "    \n",
    "    if sizes:  # Only plot if we have data\n",
    "        ax.pie(sizes, labels=labels, colors=colors, autopct='%1.0f%%', \n",
    "               startangle=90)\n",
    "        ax.set_title('Behavior Classification')\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'No data', ha='center', va='center')\n",
    "        ax.set_title('Behavior Classification')\n",
    "    \n",
    "    # 4. Summary statistics table\n",
    "    ax = axes[1, 1]\n",
    "    ax.axis('off')\n",
    "    \n",
    "    table_data = [\n",
    "        ['Metric', 'Mean ± Std', 'Range'],\n",
    "        ['Drift at 3s', f'{stats[\"drift_at_3s\"][\"mean\"]:.1f} ± {stats[\"drift_at_3s\"][\"std\"]:.1f}°', \n",
    "         f'{stats[\"drift_at_3s\"][\"min\"]:.1f} - {stats[\"drift_at_3s\"][\"max\"]:.1f}°'],\n",
    "        ['Amplitude at 3s', f'{stats[\"amp_ratio_3s\"][\"mean\"]:.0%} ± {stats[\"amp_ratio_3s\"][\"std\"]:.0%}', \n",
    "         f'{stats[\"amp_ratio_3s\"][\"min\"]:.0%} - {stats[\"amp_ratio_3s\"][\"max\"]:.0%}'],\n",
    "        ['Drift rate', f'{stats[\"drift_rate\"][\"mean\"]:.1f} ± {stats[\"drift_rate\"][\"std\"]:.1f}°/s', ''],\n",
    "        ['Persistence', f'{stats[\"death_time\"][\"mean\"]:.1f} ± {stats[\"death_time\"][\"std\"]:.1f}s', '']\n",
    "    ]\n",
    "    \n",
    "    table = ax.table(cellText=table_data, cellLoc='left', loc='center',\n",
    "                     colWidths=[0.3, 0.4, 0.3])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 1.5)\n",
    "    \n",
    "    # Style the header row\n",
    "    for i in range(3):\n",
    "        table[(0, i)].set_facecolor('#40466e')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    ax.set_title('Statistical Summary', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "def generate_statistical_report(stats):\n",
    "    \"\"\"\n",
    "    Generate report text with confidence intervals.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STATISTICAL REPORT FOR YOUR PAPER:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    drift_pct = stats['behavior_counts']['drift'] / stats['n_trials'] * 100\n",
    "    decay_pct = stats['behavior_counts']['decay'] / stats['n_trials'] * 100\n",
    "    \n",
    "    print(f\"\\nBased on {stats['n_trials']} independent trials:\")\n",
    "    \n",
    "    if drift_pct >= 70:\n",
    "        print(\"\\nShort-term memory: The bump persists for >3s without input, exhibiting\")\n",
    "        print(f\"gradual drift in {drift_pct:.0f}% of trials. At 3 seconds post-input,\")\n",
    "        print(f\"the bump maintains {stats['amp_ratio_3s']['mean']:.0%} ± {stats['amp_ratio_3s']['std']:.0%}\")\n",
    "        print(f\"of its initial amplitude while drifting {stats['drift_at_3s']['mean']:.1f} ± {stats['drift_at_3s']['std']:.1f}°.\")\n",
    "        print(f\"The mean drift rate of {stats['drift_rate']['mean']:.1f} ± {stats['drift_rate']['std']:.1f}°/s\")\n",
    "        print(\"is consistent with biological HD cells in darkness (5-15°/s; Valerio & Taube, 2016),\")\n",
    "        print(\"demonstrating biologically plausible persistent activity.\")\n",
    "        \n",
    "    elif drift_pct >= 40:\n",
    "        print(\"\\nShort-term memory: The bump persists for ~3s without input, showing\")\n",
    "        print(f\"drift behavior in {drift_pct:.0f}% of trials and decay in {decay_pct:.0f}%.\")\n",
    "        print(f\"Mean amplitude retention at 3s is {stats['amp_ratio_3s']['mean']:.0%} ± {stats['amp_ratio_3s']['std']:.0%},\")\n",
    "        print(\"indicating variable persistence quality. While some trials demonstrate\")\n",
    "        print(\"biologically plausible drift, the inconsistency represents a limitation\")\n",
    "        print(\"requiring future optimization.\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nShort-term memory: We observed persistence of the bump following input\")\n",
    "        print(f\"removal, but it is short-lived. In {decay_pct:.0f}% of trials, the bump\")\n",
    "        print(f\"amplitude decayed to {stats['amp_ratio_3s']['mean']:.0%} ± {stats['amp_ratio_3s']['std']:.0%}\")\n",
    "        print(\"within 3 seconds. This limited persistence represents a key limitation\")\n",
    "        print(\"that future work should address through improved network dynamics.\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"CONFIDENCE INTERVALS (for methods section):\")\n",
    "    print(f\"- Drift at 3s: {stats['drift_at_3s']['mean']:.1f} ± {stats['drift_at_3s']['std']:.1f}° (mean ± SD)\")\n",
    "    print(f\"- Amplitude at 3s: {stats['amp_ratio_3s']['mean']:.0%} ± {stats['amp_ratio_3s']['std']:.0%}\")\n",
    "    print(f\"- Drift rate: {stats['drift_rate']['mean']:.1f} ± {stats['drift_rate']['std']:.1f}°/s\")\n",
    "    print(f\"- n = {stats['n_trials']} trials\")\n",
    "\n",
    "\n",
    "# Run statistical analysis\n",
    "if 'trained_model' in locals():\n",
    "    print(\"Running statistical analysis of 3-second persistence...\")\n",
    "    print(\"This will take a few minutes but provides confidence intervals  .\")\n",
    "    \n",
    "    # Run multiple trials\n",
    "    stats_3s = run_3s_persistence_statistics(trained_model, n_trials=20)\n",
    "    \n",
    "    # Visualize statistics\n",
    "    plot_3s_statistics(stats_3s)\n",
    "    \n",
    "    # Generate statistical report\n",
    "    generate_statistical_report(stats_3s)\n",
    "    \n",
    "\n",
    "    \n",
    "    drift_pct = stats_3s['behavior_counts']['drift'] / stats_3s['n_trials'] * 100\n",
    "    if drift_pct >= 70:\n",
    "        print(\"✓ The bump DRIFTS after 3s (like real HD cells) - This is GOOD!\")\n",
    "        print(\"  You should emphasize this similarity to biological neurons.\")\n",
    "    elif drift_pct >= 40:\n",
    "        print(\"⚠ The bump shows MIXED behavior - both drift and decay\")\n",
    "        print(\"  Mention this variability as a current limitation.\")\n",
    "    else:\n",
    "        print(\"⚠ The bump tends to DISAPPEAR - This is a LIMITATION\")\n",
    "        print(\"  You should mention this needs to be addressed in future work.\")\n",
    "        \n",
    "else:\n",
    "    print(\"Please run the training cell first to generate a trained model!\")\n",
    "    print(\"Run Cell 7 (Quick Demo Training) to get the trained_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l7tmurcydh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test essential imports for the enhanced training demo notebook\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "\n",
    "print(\"✓ All essential imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
